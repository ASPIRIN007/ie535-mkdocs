{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>Welcome \u2014 this site contains my worked solutions.</p> <ul> <li>Chapter 1</li> <li>Chapter 2</li> <li>Chapter 3</li> <li>Chapter 4</li> </ul>"},{"location":"chapter1/","title":"Chapter 1","text":""},{"location":"chapter1/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter1/#exercises","title":"Exercises","text":"<ul> <li>Exercise 1.1*</li> </ul>"},{"location":"chapter1/ex1-1/","title":"Exercise 1.1*","text":"<p>Suppose \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) is both concave and convex. Prove \\(f\\) is affine.</p>"},{"location":"chapter1/ex1-1/#solution","title":"Solution","text":"<p>Since \\(f\\) is convex and concave, for any \\(x,y\\) and \\(0\\le \\lambda \\le 1\\), [ f(\\lambda x + (1-\\lambda)y)=\\lambda f(x)+(1-\\lambda)f(y). ]</p> <p>Define \\(g(x)=f(x)-f(0)\\). Then \\(g(0)=0\\) and the equality implies linearity (additivity + homogeneity), so \\(g(x)=a^T x\\) and \\(f(x)=f(0)+a^T x\\), i.e. affine.</p>"},{"location":"chapter1/notes/","title":"Notes","text":"<p>Key box</p> <p>These notes are typed from my handwritten Chapter 1 notes and capture the main definitions + reformulations:</p> <ol> <li>General LP formulation (objective + constraint families)  </li> <li>Turning equalities into inequalities and writing LP in matrix form  </li> <li>Local vs global minima; convexity fact  </li> <li>Piecewise-linear convex objectives and epigraph reformulation  </li> <li>Absolute value modeling (two equivalent LP reformulations)  </li> <li>Graphical (2D) geometry + solution method  </li> <li>Subspaces, span, and affine subspaces  </li> </ol>"},{"location":"chapter1/notes/#introduction-general-lp-form","title":"Introduction: General LP Form","text":"<p>In a general linear programming (LP) problem, we are given a cost vector \\(c=(c_1,\\dots,c_n)\\) and we seek to minimize a linear function \\(c^\\mathsf{T}x=\\sum_{i=1}^n c_i x_i\\) over a decision vector \\(x=(x_1,\\dots,x_n)\\), subject to linear equality/inequality constraints.</p> <p>Let \\(M_1,M_2,M_3\\) be finite index sets. For each constraint \\(i\\), we are given: - an \\(n\\)-dimensional vector \\(a_i\\), - a scalar \\(b_i\\),</p> <p>and these form the \\(i\\)-th linear constraint.</p> <p>Let \\(N_1,N_2 \\subseteq \\{1,\\dots,n\\}\\) indicate which variables are constrained to be nonnegative or nonpositive, respectively.</p> <p>Def box \u2014 General LP</p> <p>\\(\\begin{aligned} \\min\\ &amp; c^\\mathsf{T}x\\\\[2mm] \\text{s.t. }  &amp; a_i^\\mathsf{T}x \\ge b_i, &amp;&amp; i\\in M_1,\\\\ &amp; a_i^\\mathsf{T}x \\le b_i, &amp;&amp; i\\in M_2,\\\\ &amp; a_i^\\mathsf{T}x = b_i, &amp;&amp; i\\in M_3,\\\\ &amp; x_j \\ge 0, &amp;&amp; j\\in N_1,\\\\ &amp; x_j \\le 0, &amp;&amp; j\\in N_2. \\end{aligned}\\)</p> <p>Terminology</p> <ul> <li>Variables \\(x_1,\\dots,x_n\\) are decision variables.  </li> <li>A vector \\(x\\) satisfying all constraints is a feasible solution (feasible vector).  </li> <li>The set of all feasible solutions is the feasible set / feasible region.  </li> <li>If \\(j\\notin N_1\\cup N_2\\), then \\(x_j\\) is a free (unrestricted) variable.  </li> <li>The function \\(c^\\mathsf{T}x\\) is the objective function / cost function.  </li> <li>A feasible solution minimizing the objective is an optimal solution \\(x^\\star\\).  </li> <li>The value \\(c^\\mathsf{T}x^\\star\\) is the optimal cost.</li> </ul>"},{"location":"chapter1/notes/#converting-constraints-matrix-form","title":"Converting Constraints + Matrix Form","text":""},{"location":"chapter1/notes/#equality-as-two-inequalities","title":"Equality as two inequalities","text":"<p>Equality constraint equivalence</p> <p>An equality constraint can be written as two inequalities: \\(a_i^\\mathsf{T}x=b_i \\quad \\Longleftrightarrow \\quad  \\big(a_i^\\mathsf{T}x\\le b_i\\big)\\ \\text{and}\\ \\big(a_i^\\mathsf{T}x\\ge b_i\\big).\\)</p> <p>Also, constraints like \\(x_j\\ge 0\\) or \\(x_j\\le 0\\) can be viewed as special cases of linear inequalities.</p>"},{"location":"chapter1/notes/#expressing-everything-as-one-inequality-direction","title":"Expressing everything as one inequality direction","text":"<p>By multiplying some constraints by \\(-1\\), we can express the feasible set using inequalities of a single direction (e.g. all \u201c\\(\\ge\\)\u201d constraints).</p> <p>Def box \u2014 Matrix form (one-direction inequalities)</p> <p>We can write an LP in matrix form as \\(\\begin{aligned} \\min\\ &amp; c^\\mathsf{T}x\\\\ \\text{s.t. } &amp; Ax \\ge b, \\end{aligned}\\) where \\(A\\) is formed by stacking appropriate row vectors (derived from the \\(a_i^\\mathsf{T}\\)), \\(x=[x_1,\\dots,x_n]^\\mathsf{T}\\), and \\(b=[b_1,\\dots,b_m]^\\mathsf{T}\\).</p>"},{"location":"chapter1/notes/#local-vs-global-minima-convexity-fact","title":"Local vs Global Minima (Convexity Fact)","text":"<p>Def box \u2014 Local minimum</p> <p>A vector \\(x\\) is a local minimum of \\(f\\) if \\(f(x)\\le f(y)\\) for all \\(y\\) in a neighborhood of \\(x\\).</p> <p>Def box \u2014 Global minimum</p> <p>A vector \\(x\\) is a global minimum of \\(f\\) if \\(f(x)\\le f(y)\\) for all \\(y\\).</p> <p>Key fact (convexity)</p> <p>A convex function cannot have a local minimum that is not a global minimum.</p>"},{"location":"chapter1/notes/#piecewise-linear-convex-functions","title":"Piecewise-Linear Convex Functions","text":"<p>Let \\(c_1,\\dots,c_m\\in\\mathbb{R}^n\\) be vectors and \\(d_1,\\dots,d_m\\in\\mathbb{R}\\) be scalars. Consider \\(f(x)=\\max_{i=1,\\dots,m}\\big(c_i^\\mathsf{T}x+d_i\\big).\\)</p> <p>Key box</p> <p>The function \\(f(x)=\\max_i (c_i^\\mathsf{T}x+d_i)\\) is convex and is called a piecewise-linear convex function.</p> <p>Piecewise-linear convex functions can be used to approximate more general convex functions.</p>"},{"location":"chapter1/notes/#lp-with-piecewise-linear-convex-objective-epigraph-trick","title":"LP with piecewise-linear convex objective (epigraph trick)","text":"<p>Consider the problem: \\(\\min\\ \\max_{i=1,\\dots,m}(c_i^\\mathsf{T}x+d_i) \\quad \\text{s.t.}\\quad Ax\\ge b.\\)</p> <p>Introduce \\(z\\) as the smallest number satisfying \\(z\\ge c_i^\\mathsf{T}x+d_i\\) for all \\(i\\). Then we can reformulate as an LP:</p> <p>Epigraph reformulation</p> <p>\\(\\begin{aligned} \\min\\ &amp; z\\\\ \\text{s.t. } &amp; z \\ge c_i^\\mathsf{T}x+d_i,\\quad i=1,\\dots,m,\\\\ &amp; Ax\\ge b. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#constraint-of-the-form-fxle-h","title":"Constraint of the form \\(f(x)\\le h\\)","text":"<p>If \\(f\\) is piecewise-linear convex, \\(f(x)=\\max_{i=1,\\dots,m}(f_i^\\mathsf{T}x+g_i),\\) then a constraint \\(f(x)\\le h\\) can be written as the system: \\(f_i^\\mathsf{T}x+g_i\\le h,\\quad i=1,\\dots,m.\\)</p>"},{"location":"chapter1/notes/#problems-involving-absolute-values","title":"Problems Involving Absolute Values","text":"<p>Consider: \\(\\min \\sum_{i=1}^n c_i|x_i| \\quad \\text{s.t.}\\quad Ax\\ge b.\\)</p>"},{"location":"chapter1/notes/#lp-formulation-a-introduce-z_i-absolute-value-linearization","title":"LP formulation A: introduce \\(z_i\\) (absolute value linearization)","text":"<p>Absolute value via \\(z_i\\)</p> <p>Introduce \\(z_i\\ge 0\\) such that \\(z_i\\ge |x_i|\\) using: \\(x_i \\le z_i,\\qquad -x_i \\le z_i,\\qquad i=1,\\dots,n.\\) Then the LP becomes: \\(\\begin{aligned} \\min\\ &amp; \\sum_{i=1}^n c_i z_i\\\\ \\text{s.t. } &amp; Ax\\ge b,\\\\ &amp; x_i \\le z_i,\\ \\ -x_i \\le z_i,\\quad i=1,\\dots,n. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#lp-formulation-b-split-variables-xx-x-","title":"LP formulation B: split variables \\(x=x^+-x^-\\)","text":"<p>Write each \\(x_i\\) as difference of two nonnegative variables: \\(x_i=x_i^+-x_i^-\\) with \\(x_i^+,x_i^-\\ge 0\\). Then \\(|x_i|=x_i^++x_i^-\\).</p> <p>Absolute value via split variables</p> <p>Replace: \\(x = x^+ - x^-,\\) and \\(|x_i| = x_i^+ + x_i^-.\\) Then: \\(\\begin{aligned} \\min\\ &amp; \\sum_{i=1}^n c_i(x_i^+ + x_i^-)\\\\ \\text{s.t. } &amp; A x^+ - A x^- \\ge b,\\\\ &amp; x^+\\ge 0,\\ \\ x^-\\ge 0. \\end{aligned}\\)</p>"},{"location":"chapter1/notes/#graphical-representation-and-solution-2d","title":"Graphical Representation and Solution (2D)","text":""},{"location":"chapter1/notes/#core-geometry","title":"Core geometry","text":"<p>Let the feasible set be \\(P=\\{x\\mid Ax\\le b\\}.\\)</p> <p>Key box \u2014 Core geometry</p> <ul> <li>\\(P\\) is a polyhedron (intersection of half-spaces).  </li> <li>In 2D, \\(P\\) is a polygonal region (possibly unbounded).  </li> <li>Each inequality \\(a_i^\\mathsf{T}x\\le b_i\\) defines a half-plane.  </li> <li>The boundary \\(a_i^\\mathsf{T}x=b_i\\) is a line.</li> </ul> <p>Def box \u2014 Corner/vertex</p> <p>A corner / vertex is a point in \\(P\\) that cannot be written as a nontrivial convex combination of other feasible points.</p> <p>Def box \u2014 Edge/face</p> <p>An edge/face is the set of feasible points where some constraints hold with equality.</p>"},{"location":"chapter1/notes/#objective-geometry-and-the-graphical-method-2d","title":"Objective geometry and the graphical method (2D)","text":"<p>Consider objective level sets: \\(c^\\mathsf{T}x=\\alpha.\\)</p> <p>Graphical method (2D)</p> <ol> <li>Plot each constraint boundary line and choose the correct feasible half-plane.  </li> <li>Find the intersection polygon (the feasible region).  </li> <li>Slide the objective line \\(c^\\mathsf{T}x=\\alpha\\) outward (in the improving direction) until the last point of contact with the feasible region.  </li> <li>That last contact point (or contact edge) gives the optimum.</li> </ol>"},{"location":"chapter1/notes/#subspaces-and-span","title":"Subspaces and Span","text":"<p>Def box \u2014 Subspace</p> <p>A nonempty subset \\(S\\subseteq \\mathbb{R}^n\\) is a subspace of \\(\\mathbb{R}^n\\) if for every \\(x,y\\in S\\) and every \\(a,b\\in\\mathbb{R}\\), \\(ax+by\\in S.\\) If \\(S\\ne \\mathbb{R}^n\\), then \\(S\\) is a proper subspace.</p> <p>Key property</p> <p>Every subspace contains the zero vector.</p> <p>Def box \u2014 Span</p> <p>The span of vectors \\(y^1,\\dots,y^K\\in\\mathbb{R}^n\\) is the set \\(\\mathrm{span}\\{y^1,\\dots,y^K\\}   =\\left\\{\\sum_{k=1}^K a_k y^k \\;:\\; a_k\\in\\mathbb{R}\\right\\}.\\)</p>"},{"location":"chapter1/notes/#affine-subspaces","title":"Affine Subspaces","text":"<p>Let \\(S_0\\) be a subspace of \\(\\mathbb{R}^n\\) and let \\(x^0\\in\\mathbb{R}^n\\). Define: \\(S = S_0 + x^0 = \\{s + x^0 \\mid s\\in S_0\\}.\\)</p> <p>Def box \u2014 Affine subspace</p> <p>In general, \\(S\\) is not a subspace because it may not contain the zero vector. Such a translated set \\(S=S_0+x^0\\) is called an affine subspace.</p>"},{"location":"chapter2/","title":"Chapter 2","text":""},{"location":"chapter2/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter2/#doubts","title":"Doubts","text":"<ul> <li>Doubts</li> </ul>"},{"location":"chapter2/doubts/","title":"Doubt for theorem 2.5","text":""},{"location":"chapter2/doubts/#example-a-good-case-redundant-equalities-can-be-removed-when-the-feasible-set-is-nonempty","title":"Example A (Good case): redundant equalities can be removed when the feasible set is nonempty","text":"<p>We build a \\(4\\times 7\\) matrix \\(A\\) with dependent rows (rank \\(2&lt;4\\)). Rows 3 and 4 are linear combinations of rows 1 and 2.</p> <p>Let - \\(r_1 = [1,\\ 0,\\ 2,\\ 0,\\ 0,\\ 0,\\ 0]\\) - \\(r_2 = [0,\\ 1,\\ 1,\\ 0,\\ 0,\\ 0,\\ 0]\\) - \\(r_3 = r_1+r_2 = [1,\\ 1,\\ 3,\\ 0,\\ 0,\\ 0,\\ 0]\\) - \\(r_4 = 2r_1-r_2 = [2,\\ -1,\\ 3,\\ 0,\\ 0,\\ 0,\\ 0]\\)</p> <p>So \\(A= \\begin{bmatrix} 1&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;1&amp;1&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;1&amp;3&amp;0&amp;0&amp;0&amp;0\\\\ 2&amp;-1&amp;3&amp;0&amp;0&amp;0&amp;0 \\end{bmatrix}.\\)</p> <p>Now choose a feasible point \\(x\\ge 0\\), for example \\(x= \\begin{bmatrix} 2\\\\ 1\\\\ 3\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}.\\)</p> <p>Compute \\(b=Ax\\): - Row 1: \\(1(2)+2(3)=8\\) - Row 2: \\(1(1)+1(3)=4\\) - Row 3: \\(8+4=12\\) - Row 4: \\(2\\cdot 8-4=12\\)</p> <p>Hence \\(b= \\begin{bmatrix} 8\\\\ 4\\\\ 12\\\\ 12 \\end{bmatrix}.\\)</p> <p>Define \\(P=\\{x\\in\\mathbb{R}^7 \\mid Ax=b,\\ x\\ge 0\\}.\\)</p> <p>The equality system \\(Ax=b\\) corresponds to: 1. \\(x_1+2x_3=8\\) 2. \\(x_2+x_3=4\\) 3. \\(x_1+x_2+3x_3=12\\) 4. \\(2x_1-x_2+3x_3=12\\) and \\(x\\ge 0\\).</p> <p>Now define the reduced system (keep only rows 1 and 2): \\(Q=\\{x\\in\\mathbb{R}^7 \\mid r_1x=8,\\ r_2x=4,\\ x\\ge 0\\}.\\)</p> <p>Why \\(P=Q\\) (key point): - If \\(x\\in P\\), then \\(x\\) satisfies all four equations, so it satisfies the first two \\(\\Rightarrow P\\subseteq Q\\). - If \\(x\\in Q\\), then:   - Adding eqn (1)+(2) gives \\((r_1+r_2)x=8+4=12\\), but \\(r_1+r_2=r_3\\), so eqn (3) holds automatically.   - Taking \\(2\\cdot\\)(1)\\(-\\)(2) gives \\((2r_1-r_2)x=16-4=12\\), but \\(2r_1-r_2=r_4\\), so eqn (4) holds automatically.   Hence \\(x\\) satisfies all four equations \\(\\Rightarrow Q\\subseteq P\\).</p> <p>Therefore \\(P=Q\\).</p>"},{"location":"chapter2/doubts/#example-b-bad-case-if-the-feasible-set-is-empty-dropping-redundant-rows-can-change-the-set","title":"Example B (Bad case): if the feasible set is empty, dropping \u201credundant\u201d rows can change the set","text":"<p>Use the same \\(A\\) as above (rows 3 and 4 are linear combinations of rows 1 and 2): \\(A= \\begin{bmatrix} 1&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;1&amp;1&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;1&amp;3&amp;0&amp;0&amp;0&amp;0\\\\ 2&amp;-1&amp;3&amp;0&amp;0&amp;0&amp;0 \\end{bmatrix}.\\)</p> <p>Now choose an inconsistent right-hand side \\(b\\) by violating \\(b_3=b_1+b_2\\): \\(b= \\begin{bmatrix} 8\\\\ 4\\\\ 13\\\\ 12 \\end{bmatrix}.\\)</p> <p>Define \\(P=\\{x\\in\\mathbb{R}^7 \\mid Ax=b,\\ x\\ge 0\\}.\\)</p> <p>Why \\(P=\\emptyset\\): - From rows 1 and 2, any \\(x\\) satisfying them must satisfy \\((r_1+r_2)x=8+4=12\\). - But \\(r_1+r_2=r_3\\), so this forces \\(r_3x=12\\). - Row 3 also requires \\(r_3x=13\\). - Contradiction (\\(12\\ne 13\\)), so no \\(x\\) can satisfy \\(Ax=b\\).</p> <p>Now drop rows 3 and 4 and define \\(Q=\\{x\\in\\mathbb{R}^7 \\mid r_1x=8,\\ r_2x=4,\\ x\\ge 0\\}.\\)</p> <p>\\(Q\\) is nonempty: Take \\(x_3=0\\), then eqn (1) gives \\(x_1=8\\) and eqn (2) gives \\(x_2=4\\). Set the remaining variables to zero: \\(x= \\begin{bmatrix} 8\\\\ 4\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}\\ge 0.\\)</p> <p>So \\(Q\\ne\\emptyset\\) but \\(P=\\emptyset\\).</p> <p>Conclusion: If the original feasible set is empty, removing \u201cdependent\u201d equality constraints can create new feasible points, so the nonempty assumption in Theorem 2.5 is necessary.</p>"},{"location":"chapter2/doubts/#degeneracy-can-depend-on-how-we-represent-the-same-feasible-set","title":"Degeneracy can depend on how we represent the same feasible set","text":"<p>Key box</p> <p>These examples show an important subtlety:</p> <ul> <li>The same geometric polyhedron can sometimes be written with different constraint sets.  </li> <li>Under one representation, a BFS may look degenerate (too many active constraints).  </li> <li>Under another representation, the same point may look nondegenerate.</li> </ul>"},{"location":"chapter2/doubts/#example-1-same-feasible-set-different-standard-form-representations","title":"Example 1: Same feasible set, different \u201cstandard form\u201d representations","text":"<p>Consider the (standard form style) polyhedron \\(P=\\{(x_1,x_2,x_3)\\mid x_1-x_2=0,\\ x_1+x_2+2x_3=2,\\ x_1,x_2,x_3\\ge 0\\}.\\)</p> <p>Here \\(n=3\\), there are \\(m=2\\) equality constraints, so \\(n-m=1\\). In standard form, a nondegenerate BFS should have exactly \\(n-m=1\\) variable equal to zero.</p> <ul> <li>The point \\((1,1,0)\\) is nondegenerate because exactly one variable is zero (\\(x_3=0\\)).</li> <li>The point \\((0,0,1)\\) is degenerate because two variables are zero (\\(x_1=x_2=0\\)).</li> </ul> <p>Now write the same polyhedron using fewer nonnegativity constraints: \\(P=\\{(x_1,x_2,x_3)\\mid x_1-x_2=0,\\ x_1+x_2+2x_3=2,\\ x_1\\ge 0,\\ x_3\\ge 0\\}.\\)</p> <p>What changed?</p> <p>We dropped the explicit constraint \\(x_2\\ge 0\\). (Because \\(x_2=x_1\\) from \\(x_1-x_2=0\\), the nonnegativity of \\(x_2\\) is implied by \\(x_1\\ge 0\\).)</p> <p>Under this second representation, the point \\((0,0,1)\\) becomes nondegenerate: - At \\((0,0,1)\\), we now have only three active constraints:   - \\(x_1-x_2=0\\) (active as equality)   - \\(x_1+x_2+2x_3=2\\) (active as equality)   - \\(x_1\\ge 0\\) active because \\(x_1=0\\) - There is no longer an explicit \\(x_2\\ge 0\\) constraint to be active.</p> <p>So the \u201cdegeneracy label\u201d of the same BFS can change when we rewrite constraints.</p>"},{"location":"chapter2/doubts/#example-2-adding-redundant-inequalities-can-force-degeneracy","title":"Example 2: Adding redundant inequalities can force degeneracy","text":"<p>Start with a standard form polyhedron \\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\) with \\(A\\in\\mathbb{R}^{m\\times n}\\).</p> <p>Let \\(x^*\\) be a nondegenerate BFS under this representation. That means: - exactly \\(n-m\\) components of \\(x^*\\) are equal to \\(0\\), and - the number of active constraints at \\(x^*\\) is exactly \\(n\\).</p> <p>Now represent the same feasible set by converting \\(Ax=b\\) into two-sided inequalities: \\(P=\\{x\\mid Ax\\ge b,\\ -Ax\\ge -b,\\ x\\ge 0\\}.\\)</p> <p>What happens at \\(x^*\\) now?</p> <p>At any feasible point, \\(Ax=b\\) implies both \\(Ax\\ge b\\) and \\(-Ax\\ge -b\\) hold with equality. So we add \\(2m\\) active inequality constraints automatically.</p> <p>At the point \\(x^*\\): - we still have the \\(n-m\\) active constraints from \\(x\\ge 0\\) (the zero variables), - and now we also have \\(2m\\) active constraints from the two-sided inequality representation of \\(Ax=b\\).</p> <p>Total active constraints at \\(x^*\\): \\((n-m) + 2m = n+m,\\) which is strictly larger than \\(n\\) (since \\(m&gt;0\\)).</p> <p>Therefore, under this second representation, \\(x^*\\) becomes degenerate.</p> <p>Conclusion</p> <p>A BFS that is degenerate under one representation might be nondegenerate under another.</p> <p>However (important caveat): if a BFS is degenerate under one standard form representation, it can be shown it remains degenerate under every standard form representation of the same polyhedron.</p>"},{"location":"chapter2/doubts/#confusion-between-general-and-standard-form-of-polyhedron-and-number-of-constraints","title":"Confusion between general and standard form of polyhedron and number of constraints","text":"<p>Clarification: \\(m&lt;n\\) does not mean \u201cno feasible points\u201d</p> <p>In the paragraph after Definition 2.9, \\(m\\) denotes the total number of constraints used to define a polyhedron in \\(\\mathbb{R}^n\\) (equalities + inequalities).</p> <p>A basic solution (Definition 2.9) requires that among the constraints active at \\(x^\\*\\) there are \\(n\\) linearly independent ones. Therefore, at any point, \\(\\#\\{\\text{active constraints}\\}\\le m.\\)</p> <p>If \\(m&lt;n\\), then \\(\\#\\{\\text{active constraints at }x\\}&lt;n\\) for every \\(x\\), so it is impossible to have \\(n\\) linearly independent active constraints. Hence there are no basic solutions and no basic feasible solutions.</p> <p>This does not mean that the feasible set is empty. The polyhedron may still have feasible points (often infinitely many); it simply has no \u201ccorners/vertices\u201d in the sense of Definition 2.9.</p> <p>Why this is not contradictory with standard form (\\(Ax=b,\\ x\\ge 0\\))</p> <p>In standard form, \\(P=\\{x\\in\\mathbb{R}^n \\mid Ax=b,\\ x\\ge 0\\},\\) the total number of constraints is \\(m+n\\) (the \\(m\\) equalities plus the \\(n\\) nonnegativity inequalities). Thus there are always at least \\(n\\) constraints available, so basic/basic-feasible solutions can exist, and the construction \u201cset \\(n-m\\) variables to zero\u201d makes sense.</p>"},{"location":"chapter2/notes2/","title":"Notes","text":""},{"location":"chapter2/notes2/#21-polyhedra-and-convex-sets","title":"2.1 Polyhedra and Convex Sets","text":"<p>Key box</p> <p>Section 2.1 sets up the geometry language used throughout LP:</p> <ol> <li>A polyhedron is the feasible set of finitely many linear inequalities  </li> <li>Bounded vs unbounded sets (can the feasible region extend to infinity?)  </li> <li>Hyperplanes (equalities) and halfspaces (inequalities)  </li> <li>Convexity: the line segment between feasible points stays feasible  </li> <li>Convex combinations and the convex hull </li> <li>Closure facts (Theorem 2.1): intersections preserve convexity; polyhedra are convex  </li> </ol>"},{"location":"chapter2/notes2/#polyhedra-feasible-sets-of-lp-constraints","title":"Polyhedra (feasible sets of LP constraints)","text":"<p>Def box \u2014 Polyhedron</p> <p>A polyhedron is any set that can be written as \\(P=\\{x\\in\\mathbb{R}^n \\mid Ax \\ge b\\},\\) i.e., the set of vectors satisfying finitely many linear inequalities.</p> <p>Interpretation: each inequality is a \u201ccut\u201d of the space; the feasible region is what remains after applying all cuts.</p>"},{"location":"chapter2/notes2/#boundedness","title":"Boundedness","text":"<p>Def box \u2014 Bounded set</p> <p>A set \\(S\\subseteq\\mathbb{R}^n\\) is bounded if there exists a constant \\(K\\) such that \\(|x_i|\\le K\\) for every \\(x\\in S\\) and each component \\(i\\).</p> <ul> <li>Bounded polyhedron: trapped inside some big box.  </li> <li>Unbounded polyhedron: you can move infinitely far in some direction while staying feasible.</li> </ul> <p>Why it matters later: unboundedness can lead to LPs with no finite optimum (depending on the objective direction).</p>"},{"location":"chapter2/notes2/#hyperplanes-and-halfspaces-single-linear-constraints","title":"Hyperplanes and Halfspaces (single linear constraints)","text":"<p>Let \\(a\\neq 0\\) and \\(b\\in\\mathbb{R}\\).</p> <p>Def box \u2014 Hyperplane</p> <p>The hyperplane with normal \\(a\\) and offset \\(b\\) is \\(H=\\{x\\in\\mathbb{R}^n \\mid a^\\mathsf{T}x=b\\}.\\)</p> <p>Def box \u2014 Halfspace</p> <p>The halfspace defined by the inequality is \\(S=\\{x\\in\\mathbb{R}^n \\mid a^\\mathsf{T}x\\ge b\\}.\\)</p> <p>Key geometric facts - The hyperplane \\(a^\\mathsf{T}x=b\\) is the boundary of the halfspace \\(a^\\mathsf{T}x\\ge b\\). - The vector \\(a\\) is perpendicular (normal) to the hyperplane:</p> <p>If \\(x,y\\in H\\), then \\(a^\\mathsf{T}x=b\\) and \\(a^\\mathsf{T}y=b\\), so   \\(a^\\mathsf{T}(x-y)=0,\\)   meaning any direction along the hyperplane is orthogonal to \\(a\\).</p> <p>Polyhedron viewpoint \\(P=\\{x\\mid Ax\\ge b\\}\\) is the intersection of finitely many halfspaces (one per row of \\(A\\)).</p>"},{"location":"chapter2/notes2/#convex-sets-the-main-structural-property","title":"Convex Sets (the main structural property)","text":"<p>Def box \u2014 Convex set</p> <p>A set \\(S\\subseteq\\mathbb{R}^n\\) is convex if for any \\(x,y\\in S\\) and any \\(\\lambda\\in[0,1]\\), \\(\\lambda x + (1-\\lambda)y\\in S.\\) (Equivalently: the whole line segment between any two points in \\(S\\) lies in \\(S\\).)</p> <p>Why convexity matters for LP - If \\(x\\) and \\(y\\) are feasible, then any \u201cmix\u201d of them is feasible. - This property is fundamental for later results like \u201can optimum occurs at a corner/extreme point.\u201d</p>"},{"location":"chapter2/notes2/#convex-combinations-and-convex-hull","title":"Convex combinations and convex hull","text":"<p>Def box \u2014 Convex combination</p> <p>A vector \\(z\\) is a convex combination of \\(x^1,\\dots,x^k\\) if \\(z=\\sum_{i=1}^k \\lambda_i x^i,\\) where \\(\\lambda_i\\ge 0\\) and \\(\\sum_{i=1}^k \\lambda_i = 1.\\)</p> <p>Def box \u2014 Convex hull</p> <p>The convex hull of points \\(x^1,\\dots,x^k\\) is the set of all their convex combinations: \\(\\mathrm{conv}\\{x^1,\\dots,x^k\\} = \\left\\{\\sum_{i=1}^k \\lambda_i x^i \\; \\middle|\\; \\lambda_i\\ge 0,\\ \\sum_{i=1}^k\\lambda_i=1\\right\\}.\\) It is the smallest convex set containing those points.</p>"},{"location":"chapter2/notes2/#theorem-21-closure-properties-youll-use-repeatedly","title":"Theorem 2.1 (closure properties you\u2019ll use repeatedly)","text":"<p>Theorem box \u2014 Basic convexity facts</p> <ol> <li>The intersection of convex sets is convex.  </li> <li>Every polyhedron is convex.    (Halfspaces are convex, and a polyhedron is an intersection of halfspaces.)  </li> <li>If \\(S\\) is convex and \\(x^1,\\dots,x^k\\in S\\), then every convex combination \\(\\sum_{i=1}^k \\lambda_i x^i\\) lies in \\(S\\).  </li> <li>The convex hull of finitely many points is convex.</li> </ol> <p>Proof idea (what to remember)</p> <ul> <li>Halfspace convexity: if \\(a^\\mathsf{T}x\\ge b\\) and \\(a^\\mathsf{T}y\\ge b\\), then \\(a^\\mathsf{T}(\\lambda x+(1-\\lambda)y)   =\\lambda a^\\mathsf{T}x+(1-\\lambda)a^\\mathsf{T}y   \\ge \\lambda b+(1-\\lambda)b=b.\\) </li> <li>Intersections preserve convexity: if the segment stays in each set, it stays in their intersection.</li> </ul> <p>Section 2.1 \u2014 Exam checklist</p> <ul> <li>A feasible set of linear inequalities is a polyhedron: \\(P=\\{x\\mid Ax\\ge b\\}\\).  </li> <li>Each inequality defines a halfspace; equalities define hyperplanes.  </li> <li>Polyhedra are convex (intersection of convex halfspaces).  </li> <li>Bounded means contained in a box; unbounded means it extends to infinity.  </li> <li>Convex combination and convex hull formalize \u201cmixing\u201d feasible points.</li> </ul>"},{"location":"chapter2/notes2/#22-extreme-points-vertices-and-basic-feasible-solutions","title":"2.2 Extreme Points, Vertices, and Basic Feasible Solutions","text":"<p>Key box</p> <p>Section 2.2 formalizes what a \u201ccorner\u201d of a polyhedron means, in three equivalent ways:</p> <ol> <li>Extreme point (purely geometric: cannot be written as a nontrivial convex combination)  </li> <li>Vertex (optimization view: unique optimizer for some linear objective)  </li> <li>Basic feasible solution (BFS) (algebraic test: \\(n\\) linearly independent active constraints)  </li> </ol> <p>Main result: Extreme points = vertices = BFS (Theorem 2.2). It also defines adjacent basic solutions (sets up simplex \u201cmove along an edge\u201d).</p>"},{"location":"chapter2/notes2/#221-extreme-points","title":"2.2.1 Extreme points","text":"<p>Def box \u2014 Extreme point</p> <p>Let \\(P\\) be a convex set (in particular, a polyhedron). A point \\(x\\in P\\) is an extreme point of \\(P\\) if it cannot be expressed as a nontrivial convex combination of two distinct points of \\(P\\).</p> <p>Equivalently: if \\(y,z\\in P\\) and \\(0\\le \\lambda \\le 1\\) satisfy \\(x=\\lambda y+(1-\\lambda)z,\\) then either \\(x=y\\), or \\(x=z\\), or \\(\\lambda\\in\\{0,1\\}\\).</p> <p>Geometric meaning: extreme points are the true \u201ccorners\u201d \u2014 you cannot obtain them by \u201cmixing\u201d two other feasible points.</p>"},{"location":"chapter2/notes2/#222-vertices-supporting-hyperplane-lp-viewpoint","title":"2.2.2 Vertices (supporting-hyperplane / LP viewpoint)","text":"<p>Def box \u2014 Vertex</p> <p>Let \\(P\\) be a polyhedron. A point \\(x\\in P\\) is a vertex of \\(P\\) if it is the unique optimal solution of some linear program with feasible set \\(P\\).</p> <p>That is, there exists a vector \\(c\\) such that \\(x\\) is the unique minimizer of \\(\\min\\{c^\\mathsf{T}u \\mid u\\in P\\}.\\)</p> <p>Geometric meaning: there is a supporting hyperplane (a level set of a linear objective) that touches \\(P\\) only at \\(x\\).</p>"},{"location":"chapter2/notes2/#223-active-constraints-and-enough-equalities-to-pin-down-a-point","title":"2.2.3 Active constraints and \u201cenough equalities to pin down a point\u201d","text":"<p>Let the polyhedron be written as \\(P=\\{x\\in\\mathbb{R}^n \\mid a_i^\\mathsf{T}x \\ge b_i,\\ i=1,\\dots,m\\}.\\)</p> <p>At a point \\(x\\in P\\), constraint \\(i\\) is active if it holds with equality: \\(a_i^\\mathsf{T}x=b_i.\\)</p> <p>Terminology \u2014 Active set</p> <p>The active set at \\(x\\) is the index set \\(I(x)=\\{i\\in\\{1,\\dots,m\\} \\mid a_i^\\mathsf{T}x=b_i\\}.\\)</p> <p>Key idea: if the active constraints at \\(x\\) include \\(n\\) linearly independent normals, then those equalities determine \\(x\\) uniquely (they \u201cpin down\u201d the point like a corner).</p>"},{"location":"chapter2/notes2/#224-basic-solutions-and-basic-feasible-solutions","title":"2.2.4 Basic solutions and basic feasible solutions","text":"<p>Def box \u2014 Basic feasible solution (BFS)</p> <p>A feasible point \\(x\\in P\\) is a basic feasible solution if among the active constraints at \\(x\\), there exist \\(n\\) linearly independent constraints.</p> <p>(Equivalently: the active constraint normals span \\(\\mathbb{R}^n\\).)</p> <p>Remark \u2014 Basic solution vs BFS</p> <p>Often one forms a basic solution by selecting \\(n\\) linearly independent constraints, solving them as equalities to obtain a unique candidate \\(x\\), and then checking feasibility.</p> <ul> <li>If the resulting \\(x\\) satisfies all constraints, it is a basic feasible solution.  </li> <li>If it violates some constraints, it is a basic solution but not feasible.</li> </ul> <p>Important remark (representation issue)</p> <p>Whether a point is a basic solution can depend on how the polyhedron is written (which constraints you include, redundant constraints, etc.).</p> <p>However, the main theorem below shows that BFS are the same as extreme points, so the property \u201cbeing a BFS\u201d is ultimately geometric (representation-independent).</p>"},{"location":"chapter2/notes2/#225-main-equivalence-theorem","title":"2.2.5 Main equivalence theorem","text":"<p>Theorem box \u2014 Extreme point = vertex = BFS</p> <p>Let \\(P\\) be a polyhedron. For a point \\(x\\in P\\), the following are equivalent:</p> <ol> <li>\\(x\\) is a vertex of \\(P\\).  </li> <li>\\(x\\) is an extreme point of \\(P\\).  </li> <li>\\(x\\) is a basic feasible solution of \\(P\\).  </li> </ol> <p>Why this theorem matters - It justifies the \u201ccorner\u201d viewpoint in three ways:   - geometry: extreme point,   - optimization: vertex,   - algebra: BFS (what algorithms can test and move between).</p>"},{"location":"chapter2/notes2/#226-finiteness-of-basic-solutions","title":"2.2.6 Finiteness of basic solutions","text":"<p>Key fact \u2014 There are finitely many basic solutions</p> <p>A polyhedron defined by finitely many constraints has only finitely many ways to choose \\(n\\) linearly independent constraints.</p> <p>Therefore, the number of basic solutions (and hence BFS / extreme points) is finite.</p>"},{"location":"chapter2/notes2/#227-adjacency-neighbors-and-edges","title":"2.2.7 Adjacency (neighbors) and edges","text":"<p>Def box \u2014 Adjacent basic solutions</p> <p>Two distinct basic solutions are adjacent if they share \\(n-1\\) linearly independent active constraints.</p> <p>Geometric meaning</p> <p>If two basic feasible solutions are adjacent, the line segment joining them lies on an edge of the polyhedron. (This is the geometric backbone of simplex: move from one BFS to an adjacent BFS along an edge.)</p> <p>Section 2.2 \u2014 Exam checklist</p> <ul> <li>Know the three corner notions:</li> <li>Extreme point = cannot be written as a nontrivial convex combination  </li> <li>Vertex = unique optimizer for some linear objective  </li> <li>BFS = \\(n\\) linearly independent active constraints at the point  </li> <li>Be able to state: Extreme point \u21d4 Vertex \u21d4 BFS.  </li> <li>Know adjacency: share \\(n-1\\) independent active constraints (neighbors along an edge).</li> </ul>"},{"location":"chapter2/notes2/#23-polyhedra-in-standard-form","title":"2.3 Polyhedra in Standard Form","text":"<p>Key box</p> <p>Section 2.3 specializes the geometry of Section 2.2 to the standard form feasible set:</p> <ol> <li>Standard form polyhedron: \\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\) </li> <li>Basis and partition into basic vs nonbasic variables  </li> <li>Constructing a basic solution by setting \\(n-m\\) variables to zero  </li> <li>Basic feasible solution (BFS) = basic solution that also satisfies \\(x\\ge 0\\) </li> <li>A basic solution has at most \\(m\\) nonzero components  </li> <li>Adjacent bases (differ by one column) correspond to \u201cneighbor\u201d corners (sets up simplex)  </li> <li>Assuming \\(\\mathrm{rank}(A)=m\\) is no loss of generality (redundant equalities can be removed)</li> </ol>"},{"location":"chapter2/notes2/#standard-form-feasible-set","title":"Standard form feasible set","text":"<p>Def box \u2014 Standard form polyhedron</p> <p>A standard form feasible set is \\(P=\\{x\\in\\mathbb{R}^n \\mid Ax=b,\\ x\\ge 0\\},\\) where \\(A\\in\\mathbb{R}^{m\\times n}\\) and \\(b\\in\\mathbb{R}^m\\).</p> <p>Standing assumption (used throughout)</p> <p>Often we assume \\(\\mathrm{rank}(A)=m\\) (the \\(m\\) equality constraints are linearly independent) and \\(m\\le n\\).</p>"},{"location":"chapter2/notes2/#bases-and-basic-variables","title":"Bases and basic variables","text":"<p>Let \\(A_1,\\dots,A_n\\) denote the columns of \\(A\\).</p> <p>Def box \u2014 Basis (column basis)</p> <p>A set of indices \\(B\\subseteq\\{1,\\dots,n\\}\\) with \\(|B|=m\\) is a basis if the columns \\(\\{A_j\\}_{j\\in B}\\) are linearly independent.</p> <p>Notation</p> <ul> <li>The basis matrix is \\(A_B\\in\\mathbb{R}^{m\\times m}\\) formed by the columns indexed by \\(B\\).  </li> <li>The remaining indices are \\(N=\\{1,\\dots,n\\}\\setminus B\\).  </li> <li>Variables \\(\\{x_j\\}_{j\\in B}\\) are basic variables; variables \\(\\{x_j\\}_{j\\in N}\\) are nonbasic variables.</li> </ul>"},{"location":"chapter2/notes2/#basic-solutions","title":"Basic solutions","text":"<p>In standard form, the equalities \\(Ax=b\\) are always active, and the only inequalities are \\(x\\ge 0\\). A \u201ccorner candidate\u201d is obtained by activating \\(n-m\\) of the nonnegativity constraints, i.e., setting \\(n-m\\) variables to zero.</p> <p>Def box \u2014 Basic solution (associated with a basis \\(B\\))</p> <p>Given a basis \\(B\\) (so \\(A_B\\) is invertible), define a vector \\(x\\) by \\(x_N=0,\\) and \\(A_B x_B=b,\\) i.e., \\(x_B=A_B^{-1}b.\\) This \\(x\\) is called the basic solution associated with \\(B\\).</p> <p>Key property</p> <p>Any basic solution has at most \\(m\\) nonzero components, because \\(x_N=0\\) and only the \\(m\\) basic variables can be nonzero.</p>"},{"location":"chapter2/notes2/#basic-feasible-solutions-bfs","title":"Basic feasible solutions (BFS)","text":"<p>Def box \u2014 Basic feasible solution (BFS)</p> <p>A basic feasible solution is a basic solution that is feasible: \\(x\\ge 0.\\)</p> <p>Interpretation</p> <ul> <li>A basis always produces a basic solution via \\(x_B=A_B^{-1}b,\\ x_N=0\\).  </li> <li>That basic solution may be infeasible (some component negative).  </li> <li>If it satisfies \\(x\\ge 0\\), it is a BFS (a \u201ccorner\u201d of \\(P\\)).</li> </ul>"},{"location":"chapter2/notes2/#bases-vs-basic-solutions-not-always-one-to-one","title":"Bases vs basic solutions (not always one-to-one)","text":"<p>Remark</p> <p>Different bases can sometimes lead to the same basic solution. This typically happens when the resulting BFS has some basic variables equal to zero (degeneracy). (Example: if \\(b=0\\), then every basis yields the basic solution \\(x=0\\).)</p>"},{"location":"chapter2/notes2/#adjacency-in-standard-form-sets-up-simplex-moves","title":"Adjacency in standard form (sets up simplex moves)","text":"<p>Def box \u2014 Adjacent bases</p> <p>Two bases \\(B\\) and \\(B'\\) are adjacent if they differ in exactly one index, i.e., \\(|B\\cap B'|=m-1.\\)</p> <p>Geometric meaning</p> <p>Adjacent bases correspond to swapping one basic variable with one nonbasic variable. When this changes the basic solution, it moves to a neighboring corner along an edge of the feasible set.</p>"},{"location":"chapter2/notes2/#full-row-rank-assumption-is-no-loss-of-generality","title":"Full row rank assumption is no loss of generality","text":"<p>Theorem box \u2014 Removing redundant equalities</p> <p>Consider \\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\) and suppose \\(P\\) is nonempty. If \\(\\mathrm{rank}(A)=k&lt;m\\), then some equality constraints are redundant. There exists a matrix \\(D\\in\\mathbb{R}^{k\\times n}\\) with \\(\\mathrm{rank}(D)=k\\) and a vector \\(f\\in\\mathbb{R}^k\\) such that \\(\\{x\\mid Ax=b,\\ x\\ge 0\\}=\\{x\\mid Dx=f,\\ x\\ge 0\\}.\\)</p> <p>Takeaway</p> <p>We can assume \\(\\mathrm{rank}(A)=m\\) (independent equality constraints) without changing the feasible set, as long as the feasible set is nonempty.</p> <p>Section 2.3 \u2014 Exam checklist</p> <ul> <li>Standard form: \\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\).  </li> <li>Basis \\(B\\): choose \\(m\\) linearly independent columns \\(\\Rightarrow A_B\\) invertible.  </li> <li>Basic solution: \\(x_N=0\\), \\(x_B=A_B^{-1}b\\).  </li> <li>BFS: basic solution with \\(x\\ge 0\\).  </li> <li>Any basic solution has at most \\(m\\) nonzeros.  </li> <li>Adjacent bases differ by one column (simplex \u201cpivot\u201d idea).  </li> <li>Redundant equalities can be removed \\(\\Rightarrow\\) assume \\(\\mathrm{rank}(A)=m\\).</li> </ul>"},{"location":"chapter2/notes2/#24-degeneracy","title":"2.4 Degeneracy","text":"<p>Key box</p> <p>In Section 2.4 we study degeneracy, i.e., when a \u201ccorner\u201d is pinned down by more constraints than necessary.</p> <ol> <li>A basic solution in \\(\\mathbb{R}^n\\) is determined by (at least) \\(n\\) active constraints  </li> <li>Degenerate means more than \\(n\\) constraints are active at the basic solution  </li> <li>In standard form \\(Ax=b,\\ x\\ge 0\\): degeneracy shows up as extra zero variables beyond the required \\(n-m\\) </li> <li>Consequence: multiple bases can represent the same BFS (important later for simplex behavior)</li> </ol>"},{"location":"chapter2/notes2/#active-constraints-at-a-point","title":"Active constraints at a point","text":"<p>For a polyhedron \\(P=\\{x\\in\\mathbb{R}^n \\mid a_i^\\mathsf{T}x\\ge b_i,\\ i=1,\\dots,m\\}\\), constraint \\(i\\) is active at \\(x\\) if \\(a_i^\\mathsf{T}x=b_i\\).</p> <p>Def box \u2014 Degenerate / nondegenerate basic feasible solution</p> <p>Let \\(P\\subseteq \\mathbb{R}^n\\) be a polyhedron and let \\(x\\) be a basic feasible solution of \\(P\\).</p> <ul> <li>\\(x\\) is nondegenerate if it has exactly \\(n\\) active constraints.  </li> <li>\\(x\\) is degenerate if it has more than \\(n\\) active constraints.</li> </ul> <p>Standard form interpretation</p> <p>For \\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\) with \\(A\\in\\mathbb{R}^{m\\times n}\\) and \\(\\mathrm{rank}(A)=m\\): - The \\(m\\) equalities \\(Ax=b\\) are always active. - You need \\(n-m\\) more active constraints from \\(x_i\\ge 0\\), i.e., at least \\(n-m\\) variables equal to \\(0\\). - A BFS is degenerate if more than \\(n-m\\) variables are zero (i.e., \u201cextra\u201d nonnegativity constraints are active).</p> <p>Example (typical degeneracy pattern)</p> <p>In standard form, if \\(n-m=3\\) but at a BFS you observe \\(4\\) (or more) zero components, then the BFS is degenerate.</p> <p>Why degeneracy matters</p> <p>Degeneracy is the main reason: - distinct bases can yield the same BFS, and - Degeneracy of a basic feasible solution is not in general, a geometric property but rather it may depend on the particular representation of polyhedron.  - A basic feasible solution which is non-degenerate under one representation can be degenerate under other representatio.(See doubts section)</p>"},{"location":"chapter2/notes2/#25-existence-of-extreme-points","title":"2.5 Existence of Extreme Points","text":"<p>Key box</p> <p>This section answers: When does a nonempty polyhedron have at least one extreme point?</p> <ol> <li>Introduce the idea of a polyhedron containing a line </li> <li>Main criterion: a nonempty polyhedron has an extreme point iff it does not contain a line</li> </ol> <p>Def box \u2014 Polyhedron contains a line</p> <p>A polyhedron \\(P\\) contains a line if there exist some \\(x^0\\in P\\) and a nonzero direction \\(d\\neq 0\\) such that \\(x^0+\\lambda d\\in P\\) for every \\(\\lambda\\in\\mathbb{R}\\).</p> <p>(So you can move in both \\(+d\\) and \\(-d\\) directions forever and remain feasible.)</p> <p>Theorem box \u2014 Existence of extreme points</p> <p>Let \\(P\\) be a nonempty polyhedron. Then:</p> <p>\\(P\\) has at least one extreme point \\(\\Longleftrightarrow\\) \\(P\\) does not contain a line.</p> <p>Geometric meaning</p> <ul> <li>If \\(P\\) contains a line, it has a \u201cflat direction\u201d in both ways, so you cannot get a true corner.  </li> <li>If \\(P does not contain a line\\), then \\(P\\) has at least one corner (an extreme point / BFS).</li> </ul>"},{"location":"chapter2/notes2/#26-optimality-of-extreme-points","title":"2.6 Optimality of Extreme Points","text":"<p>Key box</p> <p>This section links geometry to optimization:</p> <ol> <li>Under mild conditions, if the LP is not unbounded, an optimal extreme point exists </li> <li>This is the geometric reason simplex can search over corners</li> </ol> <p>Theorem box \u2014 Optimality at an extreme point (when extreme points exist)</p> <p>Let \\(P\\) be a nonempty polyhedron that has at least one extreme point. Consider the LP \\(\\min\\{c^\\mathsf{T}x \\mid x\\in P\\}.\\)</p> <p>Then exactly one of the following holds:</p> <ol> <li>The optimal cost is \\(-\\infty\\) (the problem is unbounded below), or  </li> <li>There exists an optimal solution that is an extreme point of \\(P\\).</li> </ol> <p>Corollary box \u2014 Existence of an optimal solution (general nonempty polyhedron)</p> <p>Let \\(P\\) be a nonempty polyhedron and consider \\(\\min\\{c^\\mathsf{T}x \\mid x\\in P\\}\\). Then either:</p> <ol> <li>The optimal cost is \\(-\\infty\\), or  </li> <li>There exists at least one optimal solution (not necessarily unique).</li> </ol> <p>How to read this</p> <ul> <li>If a finite optimum is attained and \\(P\\) has extreme points, you can look for an optimal extreme point.  </li> <li>If \\(P\\) has no extreme points, the geometry is \u201cline-like,\u201d and the behavior is governed by that line direction.</li> </ul>"},{"location":"chapter2/notes2/#27-representation-of-bounded-polyhedra","title":"2.7 Representation of Bounded Polyhedra*","text":"<p>Key box</p> <p>This section gives a powerful \u201cvertex representation\u201d of bounded feasible sets:</p> <ol> <li>A bounded polyhedron (a polytope) is completely determined by its extreme points </li> <li>Every point in a bounded polyhedron can be written as a convex combination of extreme points  </li> <li>This gives the V-representation (by vertices) vs H-representation (by inequalities)</li> </ol> <p>Theorem box \u2014 Bounded polyhedron = convex hull of extreme points</p> <p>Let \\(P\\) be a nonempty bounded polyhedron. Let \\(V\\) be the set of extreme points of \\(P\\).</p> <p>Then: 1. \\(V\\) is finite, and 2. \\(P=\\mathrm{conv}(V)\\), i.e., every \\(x\\in P\\) can be written as a convex combination of extreme points:    \\(x=\\sum_{k=1}^K \\lambda_k v^k,\\)    where \\(v^k\\in V\\), \\(\\lambda_k\\ge 0\\), and \\(\\sum_{k=1}^K\\lambda_k=1\\).</p> <p>Meaning</p> <p>For bounded LP feasible regions, \u201cthe whole shape\u201d is exactly the convex hull of its corners.</p>"},{"location":"chapter2/notes2/#28-projections-of-polyhedra-fouriermotzkin-elimination","title":"2.8 Projections of Polyhedra: Fourier\u2013Motzkin Elimination","text":"<p>Key box</p> <p>This section explains how eliminating variables preserves polyhedral structure:</p> <ol> <li>Define coordinate projection \\(\\Pi_k(S)\\) </li> <li>Key fact: projection of a polyhedron is a polyhedron </li> <li>Provide an explicit elimination procedure: Fourier\u2013Motzkin elimination </li> <li>Note: constraint count can blow up (often exponentially across many eliminations)</li> </ol>"},{"location":"chapter2/notes2/#projection","title":"Projection","text":"<p>Def box \u2014 Projection map and projected set</p> <p>Let \\(\\pi_k:\\mathbb{R}^n\\to\\mathbb{R}^k\\) be the map that keeps the first \\(k\\) coordinates: \\(\\pi_k(x_1,\\dots,x_n)=(x_1,\\dots,x_k).\\)</p> <p>For a set \\(S\\subseteq\\mathbb{R}^n\\), its projection onto the first \\(k\\) coordinates is \\(\\Pi_k(S)=\\{\\pi_k(x)\\mid x\\in S\\}\\subseteq\\mathbb{R}^k.\\)</p> <p>Theorem box \u2014 Projection of a polyhedron is a polyhedron</p> <p>If \\(P\\subseteq\\mathbb{R}^n\\) is a polyhedron, then \\(\\Pi_k(P)\\subseteq\\mathbb{R}^k\\) is also a polyhedron.</p>"},{"location":"chapter2/notes2/#fouriermotzkin-elimination-eliminate-one-variable","title":"Fourier\u2013Motzkin elimination (eliminate one variable)","text":"<p>Suppose we have a system of inequalities in variables \\((x_1,\\dots,x_{n-1},x_n)\\) and we want to eliminate \\(x_n\\).</p> <p>Algorithm box \u2014 Fourier\u2013Motzkin elimination (eliminate \\(x_n\\))</p> <p>Start with inequalities of the form \\(a_i x_n + \\sum_{j=1}^{n-1} a_{ij}x_j \\ge b_i,\\quad i=1,\\dots,m.\\)</p> <ol> <li> <p>Split constraints into three groups by the coefficient of \\(x_n\\):</p> </li> <li> <p>\\(P=\\{i\\mid a_i&gt;0\\}\\) </p> </li> <li>\\(N=\\{i\\mid a_i&lt;0\\}\\) </li> <li> <p>\\(Z=\\{i\\mid a_i=0\\}\\)</p> </li> <li> <p>For \\(i\\in P\\), solve for a lower bound on \\(x_n\\):    \\(x_n \\ge \\dfrac{b_i-\\sum_{j=1}^{n-1}a_{ij}x_j}{a_i}.\\)</p> </li> <li> <p>For \\(i\\in N\\), solve for an upper bound on \\(x_n\\) (note inequality flips when dividing by \\(a_i&lt;0\\)):    \\(x_n \\le \\dfrac{b_i-\\sum_{j=1}^{n-1}a_{ij}x_j}{a_i}.\\)</p> </li> <li> <p>To eliminate \\(x_n\\), enforce that every lower bound is \\(\\le\\) every upper bound:    for each \\((i\\in P,\\ k\\in N)\\) impose    \\(\\dfrac{b_i-\\sum_{j=1}^{n-1}a_{ij}x_j}{a_i}    \\le    \\dfrac{b_k-\\sum_{j=1}^{n-1}a_{kj}x_j}{a_k}.\\)</p> </li> </ol> <p>These are inequalities involving only \\((x_1,\\dots,x_{n-1})\\).</p> <ol> <li>Keep all inequalities in \\(Z\\) unchanged (they already do not involve \\(x_n\\)).</li> </ol> <p>The resulting system describes the projection onto \\((x_1,\\dots,x_{n-1})\\).</p> <p>Complexity note</p> <p>One elimination step can create up to \\(|P|\\cdot|N|\\) new inequalities. Repeating across many variables may cause a rapid growth in the number of constraints.</p>"},{"location":"chapter2/notes2/#29-summary","title":"2.9 Summary","text":"<p>Key box</p> <p>Chapter 2 main takeaways:</p> <ol> <li>A polyhedron is an intersection of halfspaces and is convex </li> <li>Corner notions are equivalent: vertex = extreme point = BFS </li> <li>Degeneracy: a BFS can have more than \\(n\\) active constraints (extra zeros in standard form)  </li> <li>A nonempty polyhedron has an extreme point iff it does not contain a line  </li> <li>If the LP is not unbounded below and extreme points exist, an optimal extreme point exists </li> <li>Every nonempty bounded polyhedron is the convex hull of its extreme points </li> <li>Projections of polyhedra are polyhedra; Fourier\u2013Motzkin elimination performs projection by eliminating variables</li> </ol>"},{"location":"chapter3/","title":"Chapter 3","text":""},{"location":"chapter3/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter3/#doubts","title":"Doubts","text":"<ul> <li>Doubts</li> </ul>"},{"location":"chapter3/#cheatsheet","title":"Cheatsheet","text":"<ul> <li>Cheatsheet</li> </ul>"},{"location":"chapter3/cheatsheet/","title":"Chapter 3 (Bertsimas) \u2014 Simplex Method Cheat Sheet","text":""},{"location":"chapter3/cheatsheet/#1-standard-form-notation","title":"1) Standard form + notation","text":"<p>We study the LP in standard form: minimize \\(c^\\top x\\) subject to \\(Ax=b\\), \\(x\\ge 0\\), where \\(A\\in\\mathbb{R}^{m\\times n}\\) has rank \\(m\\) (rows independent).</p> <ul> <li>Choose a basis index set \\(B\\) with \\(|B|=m\\) and columns \\(A_B\\) linearly independent.</li> <li>Let \\(B:=A_B\\) (basis matrix), \\(N:=A_N\\) (nonbasic columns).</li> <li>Split variables and costs: \\(x=(x_B,x_N)\\) and \\(c=(c_B,c_N)\\).</li> </ul> <p>Constraint becomes: \\(Bx_B + Nx_N = b\\).</p>"},{"location":"chapter3/cheatsheet/#2-basic-solution-bfs","title":"2) Basic solution / BFS","text":"<p>A basic solution for basis \\(B\\) is obtained by setting \\(x_N=0\\): - \\(x_B = B^{-1}b\\) and \\(x_N=0\\).</p> <p>Basic feasible solution (BFS) condition: - BFS exists for basis \\(B\\) iff \\(B^{-1}b \\ge 0\\) (componentwise).</p> <p>Geometric meaning: BFS corresponds to a vertex (extreme point) of the feasible polyhedron.</p>"},{"location":"chapter3/cheatsheet/#3-feasible-directions-local-moves","title":"3) Feasible directions (local moves)","text":"<p>A direction \\(d\\) is feasible at a feasible point \\(x\\) if \\(\\exists \\epsilon&gt;0\\) such that \\(x+\\theta d\\) is feasible for all \\(\\theta\\in[0,\\epsilon]\\).</p> <p>For standard form \\(P=\\{x\\mid Ax=b, x\\ge 0\\}\\): - \\(Ad=0\\) - and \\(d_i\\ge 0\\) for all indices with \\(x_i=0\\).</p> <p>\u201cCone of feasible directions\u201d at \\(x\\): all feasible directions (closed under nonnegative scaling and addition).</p>"},{"location":"chapter3/cheatsheet/#4-optimality-via-feasible-directions","title":"4) Optimality via feasible directions","text":"<p>For minimizing \\(c^\\top x\\) over a polyhedron: - A feasible \\(x\\) is optimal iff \\(c^\\top d \\ge 0\\) for every feasible direction \\(d\\) at \\(x\\). - Unique optimal iff \\(c^\\top d &gt; 0\\) for every nonzero feasible direction \\(d\\) at \\(x\\).</p> <p>Intuition: if some feasible direction has negative slope, you can move a bit and improve.</p>"},{"location":"chapter3/cheatsheet/#5-reduced-costs-the-simplex-optimality-test","title":"5) Reduced costs (the simplex optimality test)","text":"<p>Given a basis \\(B\\) with BFS \\(x_B=B^{-1}b\\):</p> <p>Simplex multipliers: - \\(p^\\top = c_B^\\top B^{-1}\\) (equivalently solve \\(B^\\top p = c_B\\))</p> <p>Reduced cost of variable \\(j\\) (column \\(A_j\\)): - \\(\\bar c_j = c_j - p^\\top A_j = c_j - c_B^\\top B^{-1}A_j\\).</p> <p>Vector form (all columns at once): - \\(\\bar c^\\top = c^\\top - c_B^\\top B^{-1}A\\).</p> <p>Facts: - For basic variables \\(j\\in B\\), \\(\\bar c_j=0\\). - For minimization: if some nonbasic \\(\\bar c_j&lt;0\\), objective can be decreased by letting \\(x_j\\) enter. - If all reduced costs \\(\\bar c_j\\ge 0\\), the current BFS is optimal.</p> <p>Definition (optimal basis matrix): (a) \\(B^{-1}b\\ge 0\\) (feasible BFS) (b) \\(\\bar c^\\top = c^\\top - c_B^\\top B^{-1}A \\ge 0^\\top\\) (optimality)</p>"},{"location":"chapter3/cheatsheet/#6-one-simplex-iteration-mechanics","title":"6) One simplex iteration (mechanics)","text":"<p>Start with a feasible basis \\(B\\) (so \\(x_B=B^{-1}b\\ge 0\\), \\(x_N=0\\)).</p> <p>Step 1: Choose entering variable \\(x_j\\) with \\(\\bar c_j&lt;0\\) (any rule; often most negative).</p> <p>Step 2: Compute pivot column (direction effect on basics): - \\(u = B^{-1}A_j\\). If \\(u\\le 0\\) componentwise, then increasing \\(x_j\\) keeps \\(x_B\\) nonnegative forever: - LP is unbounded (objective \\(\\to -\\infty\\) for minimization).</p> <p>Step 3: Ratio test (step size to maintain \\(x_B\\ge 0\\)): - \\(\\theta^* = \\min_{i: u_i&gt;0} \\frac{(B^{-1}b)_i}{u_i}\\). Leaving basic variable corresponds to the minimizing index \\(i\\).</p> <p>Update along direction: - \\(x_j \\leftarrow \\theta^*\\), - \\(x_B \\leftarrow x_B - \\theta^* u\\), - and pivot: replace leaving column in \\(B\\) by \\(A_j\\).</p>"},{"location":"chapter3/cheatsheet/#7-degeneracy-and-cycling","title":"7) Degeneracy and cycling","text":"<p>Degenerate BFS: at least one basic variable is zero.</p> <p>Consequences: - Ratio test can give \\(\\theta^*=0\\) (pivot changes basis but not the point or objective). - Repeated degenerate pivots can cause cycling (in theory).</p> <p>Avoid cycling: Bland\u2019s rule or lexicographic pivoting (anti-cycling rules).</p>"},{"location":"chapter3/cheatsheet/#8-implementations-bookkeeping","title":"8) Implementations (bookkeeping)","text":"<p>Naive / full tableau: - Stores \\(B^{-1}A\\) and \\(B^{-1}b\\) explicitly. - Easy but high memory; per-iteration updates can be expensive.</p> <p>Revised simplex: - Does not store full \\(B^{-1}A\\). - Stores/factorizes \\(B\\) and computes \\(B^{-1}A_j\\) by solving linear systems. - Much better for large sparse problems.</p> <p>Key comparison: - Full tableau: memory roughly \\(O(mn)\\). - Revised: memory for basis info roughly \\(O(m^2)\\) (plus storing sparse \\(A\\)).</p>"},{"location":"chapter3/cheatsheet/#9-finding-an-initial-bfs-phase-i-big-m","title":"9) Finding an initial BFS (Phase I / Big-M)","text":"<p>If no obvious BFS:</p> <p>Two-phase (Phase I): - Add artificial variables \\(y\\ge 0\\):   \\(Ax + y = b\\), \\(x\\ge 0\\), \\(y\\ge 0\\). - Minimize \\(w=\\sum_i y_i\\). - Start with basis \\(y=b\\) (identity basis). Outcomes: - If optimal \\(w^*&gt;0\\): original LP infeasible. - If \\(w^*=0\\): feasible solution found with \\(y=0\\). Then remove artificial columns (pivot them out if still basic) and use the final Phase I basis as the starting basis for Phase II.</p> <p>Phase II: - Keep the final constraint tableau/basis from Phase I. - Replace objective by original \\(c^\\top x\\) and recompute reduced costs. - Continue simplex pivots.</p> <p>Big-M: - Minimize \\(c^\\top x + M\\sum_i y_i\\) with \\(M\\) \u201cvery large\u201d. Conceptually similar, but Phase I is cleaner numerically.</p>"},{"location":"chapter3/cheatsheet/#10-geometry-column-geometry-intuition","title":"10) Geometry (column geometry intuition)","text":"<p>With added convexity constraint \\(e^\\top x=1\\): - \\(b\\) becomes a convex combination of columns: \\(b=\\sum_i x_i A_i\\). - Each basis corresponds to a simplex formed by \\(m+1\\) points \\((A_i,c_i)\\). Pivot = swap one vertex of the simplex (move to adjacent simplex). Reduced costs correspond to \u201cheight below the dual plane\u201d; negative reduced cost means a column lies below the dual plane and can improve.</p>"},{"location":"chapter3/cheatsheet/#11-complexity-what-to-remember","title":"11) Complexity (what to remember)","text":"<p>Per-iteration work is polynomial (depends on implementation), but: - Number of pivots can be exponential in worst case (e.g., Klee\u2013Minty-type). In practice, simplex is typically fast; theory focuses on worst-case vs average-case behavior.</p>"},{"location":"chapter3/cheatsheet/#12-minimal-exam-ready-checklist","title":"12) Minimal exam-ready checklist","text":"<ul> <li>Given \\(B\\): compute \\(x_B=B^{-1}b\\) and decide feasibility.</li> <li>Compute reduced costs \\(\\bar c_j=c_j-c_B^\\top B^{-1}A_j\\) and test optimality.</li> <li>If not optimal: compute \\(u=B^{-1}A_j\\), do ratio test, pivot.</li> <li>Detect unboundedness: \\(u\\le 0\\).</li> <li>Explain degeneracy, \\(\\theta^*=0\\), and cycling avoidance.</li> <li>Explain Phase I logic: \\(w^*=0\\) gives feasibility; then Phase II optimizes original objective.</li> </ul>"},{"location":"chapter3/doubts/","title":"Quick fixes for recurring confusions","text":"<p>Key box</p> <p>This page is a running \u201cFAQ\u201d of common confusions that come up while reading Bertsimas (LP). I keep the statements clean, specify what is actually meant, and (when useful) restate the precise definition/theorem-like claim.</p>"},{"location":"chapter3/doubts/#1-how-can-a-vector-x-have-a-rank-its-not-a-matrix","title":"1) \u201cHow can a vector \\(x\\) have a rank? It\u2019s not a matrix.\u201d","text":"<p>Key box \u2014 What\u2019s going on?</p> <p>A vector does not have a rank (rank is a matrix concept). When the text/notes say \u201crank of \\(x\\) is \\(k\\)\u201d, they almost always mean: - the number of linearly independent active constraints at \\(x\\), or - the rank of some matrix built from vectors (e.g., active constraint normals), or - the dimension of an affine hull/subspace (sometimes said informally as \u201crank\u201d).</p> <p>Definition box \u2014 Active constraints (inequality form)</p> <p>For \\(P=\\{x\\mid a_i^\\top x \\ge b_i,\\ i=1,\\dots,m\\}\\), constraint \\(i\\) is active at \\(x\\in P\\) if \\(a_i^\\top x=b_i\\).</p> <p>Definition box \u2014 Rank at a point (as used in Section 2.5 / 2.8 style arguments)</p> <p>The \u201crank of \\(x\\)\u201d (informal) means: the maximum number \\(k\\) of linearly independent constraint normals among the constraints that are active at \\(x\\).</p>"},{"location":"chapter3/doubts/#2-why-does-local-optimality-imply-global-optimality-in-lp","title":"2) \u201cWhy does local optimality imply global optimality in LP?\u201d","text":"<p>Definition box \u2014 Convex set</p> <p>A set \\(S\\) is convex if for all \\(x,y\\in S\\) and all \\(\\lambda\\in[0,1]\\), \\(\\lambda x+(1-\\lambda)y \\in S\\).</p> <p>Key box \u2014 LP convexity fact</p> <ul> <li>The feasible set of an LP is convex (intersection of halfspaces/affine sets).  </li> <li>The objective \\(c^\\top x\\) is linear, hence convex. Therefore, if you cannot improve locally (no feasible descent direction), you are globally optimal.</li> </ul>"},{"location":"chapter3/doubts/#3-they-say-ctop-y-ge-v-and-ctop-z-ge-v-implies-ctop-yv-and-ctop-zv-why","title":"3) \u201cThey say \\(c^\\top y \\ge v\\) and \\(c^\\top z \\ge v\\) implies \\(c^\\top y=v\\) and \\(c^\\top z=v\\). Why?\u201d","text":"<p>Definition box \u2014 Optimal value</p> <p>If \\(P\\) is feasible, the optimal value is \\(v=\\min\\{c^\\top x\\mid x\\in P\\}\\) (for a minimization LP).</p> <p>Key box \u2014 When equality holds</p> <p>For any feasible \\(y\\in P\\), we always have \\(c^\\top y\\ge v\\). If in addition \\(y\\) is optimal, then necessarily \\(c^\\top y=v\\). Same for \\(z\\).</p> <p>Common confusion</p> <p>The implication \u201c\\(c^\\top y\\ge v\\) therefore \\(c^\\top y=v\\)\u201d is false unless you already know \\(y\\) is optimal.</p>"},{"location":"chapter3/doubts/#4-what-do-we-gain-by-writing-ctop-yv-isnt-it-just-choosing-lambda1-so-yx","title":"4) \u201cWhat do we gain by writing \\(c^\\top y=v\\)? Isn\u2019t it just choosing \\(\\lambda=1\\) so \\(y=x^*\\)?\u201d","text":"<p>Key box \u2014 What we gain</p> <p>In proofs, we usually start with an optimal point \\(x^*\\) and write it as \\(x^*=\\lambda y+(1-\\lambda)z\\) with \\(y\\neq z\\) and \\(\\lambda\\in(0,1)\\). Linearity gives: \\(c^\\top x^*=\\lambda c^\\top y+(1-\\lambda)c^\\top z\\).</p> <p>Since \\(c^\\top x^*=v\\) and also \\(c^\\top y\\ge v\\), \\(c^\\top z\\ge v\\), the only way the convex combination equals \\(v\\) is: \\(c^\\top y=v\\) and \\(c^\\top z=v\\).</p> <p>This shows both endpoints are optimal, which is the whole point (we are not setting \\(\\lambda=1\\)).</p>"},{"location":"chapter3/doubts/#5-how-does-x-is-a-cornerextreme-point-solve-a-contradiction","title":"5) \u201cHow does \u2018\\(x^*\\) is a corner/extreme point\u2019 solve a contradiction?\u201d","text":"<p>Definition box \u2014 Extreme point</p> <p>A point \\(x^*\\in P\\) is an extreme point if it cannot be written as \\(x^*=\\lambda y+(1-\\lambda)z\\) with \\(y,z\\in P\\), \\(y\\neq z\\), and \\(\\lambda\\in(0,1)\\).</p> <p>Key box \u2014 Why corners matter in linear objectives</p> <p>If \\(x^*\\) is optimal and not an extreme point, you can express it as a strict convex combination of two distinct feasible points. Linearity forces those points to also be optimal (same argument as above). Then you can keep decomposing until you reach an optimal extreme point (under the \u201cno lines / at least one extreme point exists\u201d assumptions).</p>"},{"location":"chapter3/doubts/#6-if-an-lp-has-m-constraints-and-n-variables-what-does-rank-tell-us-about-existence","title":"6) \u201cIf an LP has \\(m\\) constraints and \\(n\\) variables, what does rank tell us about existence?\u201d","text":"<p>Definition box \u2014 Consistency of \\(Ax=b\\)</p> <p>The system \\(Ax=b\\) is consistent if there exists \\(x\\) such that \\(Ax=b\\).</p> <p>Key box \u2014 Equality constraints only</p> <p>For \\(Ax=b\\): - \\(\\mathrm{rank}(A)&lt;m\\) means the rows are dependent (some equalities are redundant or inconsistent depending on \\(b\\)). - It does not automatically mean infeasible.</p> <p>Key box \u2014 Standard form feasibility is stricter</p> <p>In standard form \\(Ax=b,\\ x\\ge 0\\): - Even if \\(Ax=b\\) is consistent, there may be no nonnegative solution. - Feasibility means: \\(\\exists x\\ge 0\\) such that \\(Ax=b\\).</p>"},{"location":"chapter3/doubts/#7-set-s-is-convex-what-exactly-does-that-mean","title":"7) \u201cSet \\(S\\) is convex \u2014 what exactly does that mean?\u201d","text":"<p>Definition box \u2014 Convexity (repeat, because it\u2019s used everywhere)</p> <p>\\(S\\) is convex iff for all \\(x,y\\in S\\) and all \\(\\lambda\\in[0,1]\\), \\(\\lambda x+(1-\\lambda)y\\in S\\).</p> <p>Key box \u2014 Geometry</p> <p>Convex means: the entire line segment between any two feasible points stays feasible.</p>"},{"location":"chapter3/doubts/#8-why-do-we-introduce-reduced-costs-in-simplex","title":"8) \u201cWhy do we introduce reduced costs in simplex?\u201d","text":"<p>Definition box \u2014 Reduced cost (standard form)</p> <p>For a basis \\(B\\) and nonbasic index \\(j\\), the reduced cost is \\(\\bar c_j = c_j - c_B^\\top B^{-1}A_j\\).</p> <p>Key box \u2014 Meaning</p> <p>\\(\\bar c_j\\) is the objective\u2019s rate of change when you try to increase \\(x_j\\) from \\(0\\) while keeping \\(Ax=b\\) satisfied by adjusting basic variables.</p>"},{"location":"chapter3/doubts/#11-what-is-cycling-in-simplex-and-how-do-anticycling-rules-fix-it","title":"11) \u201cWhat is cycling in simplex and how do anticycling rules fix it?\u201d","text":"<p>Definition box \u2014 Degenerate BFS</p> <p>A basic feasible solution is degenerate if at least one basic variable equals \\(0\\).</p> <p>Definition box \u2014 Cycling</p> <p>Cycling means simplex repeats a previously visited basis and can loop forever (possible only under degeneracy).</p> <p>Key box \u2014 Why it happens</p> <p>Degeneracy can cause \\(\\theta^*=0\\) in the ratio test: basis changes but the point \\(x\\) does not move \u2192 can return to an old basis.</p> <p>Theorem box \u2014 Anticycling idea (informal)</p> <p>If a pivoting rule guarantees no basis repeats, then simplex must terminate in finitely many pivots.</p> <p>Key box \u2014 Two rules</p> <ul> <li>Lexicographic pivoting: tie-breaks so tableau increases lexicographically \u2192 no repetition.  </li> <li>Bland\u2019s rule: smallest-index entering + smallest-index leaving among ties \u2192 no cycling.</li> </ul>"},{"location":"chapter3/doubts/#12-what-is-the-auxiliary-variable-phase-i-method-and-why-minimize-sum-y_i","title":"12) \u201cWhat is the auxiliary-variable (Phase I) method, and why minimize \\(\\sum y_i\\)?\u201d","text":"<p>Definition box \u2014 Phase I (auxiliary LP)</p> <p>For \\(Ax=b,\\ x\\ge 0\\) (assume \\(b\\ge 0\\) after sign changes), introduce \\(y\\ge 0\\) and solve: $$ \\min \\sum_{i=1}^m y_i \\quad \\text{s.t.}\\quad Ax+y=b,\\ x\\ge 0,\\ y\\ge 0. $$</p> <p>Theorem box \u2014 Phase I feasibility test (core fact)</p> <p>The original LP is feasible iff the Phase I optimal value is \\(0\\).</p> <p>Key box \u2014 Why</p> <ul> <li>Always-feasible start: \\(x=0,\\ y=b\\).  </li> <li>If original feasible, then \\((x,0)\\) feasible in Phase I \u2192 objective \\(0\\).  </li> <li>Objective is \\(\\ge 0\\), so optimum is \\(0\\) exactly when we can drive \\(y\\) to \\(0\\).</li> </ul>"},{"location":"chapter3/doubts/#13-phase-i-ended-with-an-artificial-variable-still-basic-value-0-what-do-we-do","title":"13) \u201cPhase I ended with an artificial variable still basic (value 0). What do we do?\u201d","text":"<p>Key box \u2014 Degenerate cleanup step</p> <p>If some artificial \\(y_\\ell\\) is basic with value \\(0\\) at the end of Phase I:</p> <ul> <li>If the entire \\(\\ell\\)-th row has zeros in the original-variable columns, the corresponding equality is redundant \u2192 drop that constraint row.</li> <li>Otherwise, pivot in an original variable with a nonzero entry in that row so that \\(y_\\ell\\) leaves the basis.</li> </ul>"},{"location":"chapter3/doubts/#14-big-m-vs-two-phase-simplex-whats-the-difference","title":"14) \u201cBig-\\(M\\) vs two-phase simplex \u2014 what\u2019s the difference?\u201d","text":"<p>Definition box \u2014 Big-\\(M\\) objective</p> <p>Solve one LP: $$ \\min\\ c^\\top x + M\\sum_{i=1}^m y_i \\quad \\text{s.t.}\\quad Ax+y=b,\\ x\\ge 0,\\ y\\ge 0, $$ where \\(M\\) is \u201cvery large\u201d.</p> <p>Key box \u2014 Comparison</p> <ul> <li>Two-phase: clean and numerically stable in practice.  </li> <li>Big-\\(M\\): conceptually one phase, but large \\(M\\) can cause numerical issues (unless treated symbolically as in textbooks).</li> </ul>"},{"location":"chapter3/doubts/#15-why-add-the-convexity-constraint-etop-x1-in-the-geometry-section","title":"15) \u201cWhy add the convexity constraint \\(e^\\top x=1\\) in the geometry section?\u201d","text":"<p>Definition box \u2014 Convex combination weights</p> <p>If \\(x\\ge 0\\) and \\(e^\\top x=1\\), then \\(x\\) acts as weights of a convex combination.</p> <p>Key box \u2014 Column geometry meaning</p> <p>With \\(Ax=b\\) and \\(e^\\top x=1\\): - \\(b=\\sum_i x_i A_i\\) means \\(b\\) is in \\(\\mathrm{conv}\\{A_i\\}\\). - \\(z=c^\\top x=\\sum_i x_i c_i\\) means \\((b,z)\\) is in \\(\\mathrm{conv}\\{(A_i,c_i)\\}\\).</p>"},{"location":"chapter3/doubts/#16-what-is-the-requirement-line","title":"16) \u201cWhat is the requirement line?\u201d","text":"<p>Definition box \u2014 Requirement line</p> <p>For fixed \\(b\\), the requirement line is \\(\\{(b,z)\\mid z\\in\\mathbb{R}\\}\\) in \\(\\mathbb{R}^{m+1}\\).</p> <p>Key box</p> <p>Feasible solutions correspond to intersection points of this vertical line with \\(H=\\mathrm{conv}\\{(A_i,c_i)\\}\\), and the optimum is the lowest intersection point.</p>"},{"location":"chapter3/doubts/#17-what-is-the-dual-plane-and-why-is-below-the-plane-the-same-as-negative-reduced-cost","title":"17) \u201cWhat is the dual plane, and why is \u2018below the plane\u2019 the same as negative reduced cost?\u201d","text":"<p>Definition box \u2014 Dual plane (geometry picture)</p> <p>The lifted basic points \\((A_{B(i)},c_{B(i)})\\) lie on an \\(m\\)-dimensional hyperplane in \\(\\mathbb{R}^{m+1}\\) (the dual plane).</p> <p>Theorem box \u2014 Geometric meaning of reduced cost (informal)</p> <p>For minimization, a point \\((A_j,c_j)\\) lies below the dual plane \\(\\Longleftrightarrow\\) the reduced cost satisfies \\(\\bar c_j&lt;0\\).</p> <p>Key box</p> <p>Reduced cost is a signed vertical distance from the dual plane to the candidate lifted point.</p>"},{"location":"chapter3/doubts/#18-how-can-simplex-be-fast-in-practice-if-worst-case-is-exponential","title":"18) \u201cHow can simplex be fast in practice if worst-case is exponential?\u201d","text":"<p>Key box</p> <ul> <li>Worst-case constructions force simplex to visit exponentially many vertices.  </li> <li>Real LPs often have structure; with good pivot rules, simplex typically needs far fewer pivots.</li> </ul> <p>Key box \u2014 What theory separates</p> <p>Performance = (work per pivot) + (number of pivots). Revised simplex + sparsity handles the first; the second is where worst-case exponential behavior lives.</p>"},{"location":"chapter3/notes/","title":"Chapter 3 \u2014 The Simplex Method","text":"<p>Key box \u2014 Standard form + what this chapter does</p> <p>We study the simplex method for the standard form LP \\(\\min\\; c^\\top x \\ \\text{s.t.}\\ Ax=b,\\ x\\ge 0\\), where \\(A\\in\\mathbb{R}^{m\\times n}\\) has linearly independent rows (rank \\(m\\)). The feasible set is the polyhedron \\(P=\\{x\\in\\mathbb{R}^n\\mid Ax=b,\\ x\\ge 0\\}\\).</p> <p>Notation box</p> <ul> <li>\\(A_i\\) = \\(i\\)-th column of \\(A\\) </li> <li>\\(a_i^\\top\\) = \\(i\\)-th row of \\(A\\) </li> <li>\\(e\\) = all-ones vector  </li> <li>For a basis index set \\(B=\\{B(1),\\dots,B(m)\\}\\), the basis matrix is \\(B=[A_{B(1)}\\ \\cdots\\ A_{B(m)}]\\).</li> </ul>"},{"location":"chapter3/notes/#31-optimality-conditions","title":"3.1 Optimality conditions","text":""},{"location":"chapter3/notes/#311-local-improvement-is-enough-in-lp","title":"3.1.1 Local improvement is enough in LP","text":"<p>Key box \u2014 Why local = global in LP</p> <p>For LPs: - the objective \\(c^\\top x\\) is linear (hence convex), and - the feasible set \\(P\\) is convex (intersection of an affine set \\(Ax=b\\) with halfspaces \\(x\\ge 0\\)).</p> <p>Therefore, if at a feasible point you cannot move in any feasible direction that decreases the cost, that point is globally optimal.</p>"},{"location":"chapter3/notes/#312-feasible-directions","title":"3.1.2 Feasible directions","text":"<p>Definition box \u2014 Feasible direction at \\(x\\)</p> <p>A vector \\(d\\in\\mathbb{R}^n\\) is a feasible direction at \\(x\\in P\\) if there exists \\(\\varepsilon&gt;0\\) such that \\(x+\\theta d \\in P\\) for all \\(\\theta\\in[0,\\varepsilon]\\).</p> <p>Key box \u2014 What feasibility forces in standard form</p> <p>Since feasibility means both \\(Ax=b\\) and \\(x\\ge 0\\):</p> <ul> <li> <p>Equality constraints: \\(Ax=b\\) must remain true along the move, so \\(A(x+\\theta d)=b\\ \\forall\\theta \\ \\Longrightarrow\\ Ad=0\\).</p> </li> <li> <p>Nonnegativity: if a component is at zero, you cannot move it negative, so \\(x_i=0\\ \\Longrightarrow\\ d_i\\ge 0\\).</p> </li> </ul> <p>(This second condition is the clean algebraic version of Figure 3.1.)</p>"},{"location":"chapter3/notes/#313-basic-feasible-solutions-and-basic-directions","title":"3.1.3 Basic feasible solutions and \u201cbasic directions\u201d","text":"<p>Definition box \u2014 Basis and basic solution (standard form)</p> <p>Choose an index set \\(B=\\{B(1),\\dots,B(m)\\}\\) such that the matrix \\(B=[A_{B(1)}\\ \\cdots\\ A_{B(m)}]\\) is invertible. Set all nonbasic variables to zero: \\(x_j=0\\) for \\(j\\notin B\\). Then the basic variables satisfy \\(x_B=B^{-1}b\\). This \\(x\\) is a basic solution. If additionally \\(x_B\\ge 0\\), it is a basic feasible solution (BFS).</p> <p>Key box \u2014 Basic direction associated with a nonbasic index \\(j\\notin B\\)</p> <p>From a BFS, a natural \u201cedge move\u201d is to increase one nonbasic variable \\(x_j\\) from \\(0\\) while keeping all other nonbasic variables at \\(0\\).</p> <p>Construct a direction \\(d\\) by: - \\(d_j=1\\), - \\(d_i=0\\) for all other nonbasic \\(i\\neq j\\), - choose \\(d_B\\) so that the equality constraints stay satisfied: \\(Ad=0\\).</p> <p>Since \\(Ad = Bd_B + A_j = 0\\), we obtain the basic-direction formula \\(d_B=-B^{-1}A_j\\). (This is equation (3.1) in the text.)</p> <p>Intuition box</p> <p>Increasing \\(x_j\\) forces a compensating change in the basic variables so that \\(Ax=b\\) remains true.</p>"},{"location":"chapter3/notes/#314-degeneracy-a-basic-direction-might-not-be-feasible","title":"3.1.4 Degeneracy: a \u201cbasic direction\u201d might not be feasible","text":"<p>Definition box \u2014 Degeneracy</p> <p>A BFS is: - nondegenerate if \\(x_B&gt;0\\) (all basic variables strictly positive), - degenerate if some basic variable equals \\(0\\).</p> <p>Key box \u2014 Why degeneracy matters for feasibility of directions</p> <p>Even if \\(Ad=0\\), moving along \\(d\\) can violate \\(x\\ge 0\\).</p> <ul> <li> <p>If the BFS is nondegenerate (\\(x_B&gt;0\\)), then for sufficiently small \\(\\theta&gt;0\\), we still have \\(x_B+\\theta d_B \\ge 0\\),   so the basic direction is feasible.</p> </li> <li> <p>If the BFS is degenerate (some basic component is \\(0\\)), and the corresponding component of \\(d_B\\) is negative, then \\(x_B+\\theta d_B\\) becomes negative immediately for any \\(\\theta&gt;0\\).   So that \u201cbasic direction\u201d is not feasible.</p> </li> </ul> <p>Subtle point box</p> <p>Degeneracy breaks the naive implication \u201cnegative reduced cost \\(\\Rightarrow\\) feasible improving edge,\u201d because the candidate edge direction might point out of \\(P\\).</p>"},{"location":"chapter3/notes/#315-reduced-costs","title":"3.1.5 Reduced costs","text":"<p>Definition box \u2014 Reduced cost</p> <p>Along the \\(j\\)-th basic direction \\(d\\), the objective change rate is \\(c^\\top d = c_B^\\top d_B + c_j\\). Using \\(d_B=-B^{-1}A_j\\) gives \\(c^\\top d = c_j - c_B^\\top B^{-1}A_j\\). This motivates the reduced cost \\(\\bar c_j = c_j - c_B^\\top B^{-1}A_j\\).</p> <p>Key box \u2014 Interpretation</p> <ul> <li>\\(c_j\\) = direct cost change from increasing \\(x_j\\) </li> <li>\\(-c_B^\\top B^{-1}A_j\\) = induced cost from adjusting basic variables to keep \\(Ax=b\\)</li> </ul> <p>Key box \u2014 Reduced costs of basic variables are zero</p> <p>If \\(j=B(i)\\) is basic, then \\(B^{-1}A_{B(i)}=e_i\\), hence \\(\\bar c_{B(i)} = c_{B(i)} - c_B^\\top e_i = c_{B(i)}-c_{B(i)}=0\\).</p>"},{"location":"chapter3/notes/#316-example-as-in-example-31","title":"3.1.6 Example (as in Example 3.1)","text":"<p>Key box \u2014 Setup</p> <p>Consider \\(\\min\\ c_1x_1+c_2x_2+c_3x_3+c_4x_4\\) subject to \\(x_1+x_2+x_3+x_4=2\\), \\(2x_1+3x_3+4x_4=2\\), and \\(x\\ge 0\\).</p> <p>Key box \u2014 Choose a basis and compute the BFS</p> <p>Choose \\(x_1,x_2\\) basic. Then \\(B=\\begin{bmatrix}1&amp;1\\\\2&amp;0\\end{bmatrix}\\) and \\(x_3=x_4=0\\). Solve \\(Bx_B=b\\) to get \\(x_1=1,\\ x_2=1\\) (nondegenerate).</p> <p>Key box \u2014 Entering \\(x_3\\)</p> <p>For entering \\(x_3\\), with \\(A_3=(1,3)^\\top\\): \\(d_3=1,\\ d_4=0,\\ d_B=-B^{-1}A_3\\). The objective rate along this direction is \\(\\bar c_3\\).</p>"},{"location":"chapter3/notes/#317-optimality-conditions-nondegenerate-case","title":"3.1.7 Optimality conditions (nondegenerate case)","text":"<p>Theorem box \u2014 Optimality via reduced costs</p> <p>Let \\(x\\) be a BFS associated with a basis \\(B\\), and let \\(\\bar c\\) be the vector of reduced costs.</p> <ol> <li>If \\(\\bar c\\ge 0\\), then \\(x\\) is optimal.  </li> <li>If \\(x\\) is optimal and nondegenerate, then \\(\\bar c\\ge 0\\).</li> </ol> <p>Key box \u2014 Why this is true (conceptual)</p> <ul> <li>\\(\\bar c_j\\) is the slope of the objective along the \\(j\\)-th basic direction.  </li> <li>If every slope is \\(\\ge 0\\), no edge direction improves the cost \\(\\Rightarrow\\) optimal.  </li> <li>If nondegenerate and some \\(\\bar c_j&lt;0\\), that direction is feasible and decreases cost \\(\\Rightarrow\\) not optimal.</li> </ul> <p>Key box \u2014 Degenerate exception</p> <p>An optimal degenerate BFS may still have some negative reduced costs, because the corresponding basic directions might not be feasible.</p>"},{"location":"chapter3/notes/#34-anticycling-lexicography-and-blands-rule","title":"3.4 Anticycling: lexicography and Bland\u2019s rule","text":""},{"location":"chapter3/notes/#341-why-cycling-happens-degeneracy","title":"3.4.1 Why cycling happens (degeneracy)","text":"<p>Definition box \u2014 Cycling</p> <p>Cycling means simplex repeats a previously visited basis and can loop forever.</p> <p>Key box \u2014 Mechanism</p> <ul> <li>In the nondegenerate case, each pivot has \\(\\theta^*&gt;0\\), so the objective strictly decreases and no basis repeats.  </li> <li>In the degenerate case, the ratio test can give \\(\\theta^*=0\\). Then:</li> <li>the basis changes,</li> <li>the point \\(x\\) does not change,</li> <li>the objective does not improve,   so a sequence of such pivots can return to an earlier basis \\(\\Rightarrow\\) cycling.</li> </ul> <p>Key box \u2014 What anticycling rules guarantee</p> <p>Anticycling pivot rules ensure no basis repeats, hence simplex must terminate (assuming finite optimal cost).</p> <p>Key box \u2014 Useful corollary</p> <p>If the optimal cost is finite, there exists an optimal basis, i.e. a basis with \\(B^{-1}b\\ge 0\\) and reduced costs \\(\\bar c = c^\\top - c_B^\\top B^{-1}A \\ge 0\\).</p>"},{"location":"chapter3/notes/#342-lexicographic-order-definitions","title":"3.4.2 Lexicographic order (definitions)","text":"<p>Definition box \u2014 Lexicographic order</p> <p>For \\(u,v\\in\\mathbb{R}^k\\), we say \\(u\\) is lexicographically smaller than \\(v\\) (write \\(u\\prec v\\)) if: - let \\(t\\) be the first index where \\(u_t\\ne v_t\\), - then \\(u\\prec v\\) iff \\(u_t&lt;v_t\\).</p> <p>Definition box \u2014 Lexicographically positive</p> <p>\\(u\\) is lexicographically positive if \\(u\\succ 0\\) (the first nonzero component of \\(u\\) is positive).</p> <p>Example box</p> <ul> <li>\\((0,2,3,0)\\succ(0,2,1,4)\\) (first difference at index 3: \\(3&gt;1\\)).  </li> <li>\\((0,4,5,0)\\prec(1,2,1,2)\\) (first difference at index 1: \\(0&lt;1\\)).</li> </ul>"},{"location":"chapter3/notes/#343-the-lexicographic-pivoting-rule-full-tableau-form","title":"3.4.3 The lexicographic pivoting rule (full tableau form)","text":"<p>Key box \u2014 Pivot column entries</p> <p>Fix an entering column \\(j\\). Let the pivot column entries be \\(u_i=(B^{-1}A_j)_i\\).</p> <p>Definition box \u2014 Lexicographic leaving rule</p> <p>Among rows with \\(u_i&gt;0\\), normalize each candidate row by dividing by \\(u_i\\). Choose the pivot row \\(\\ell\\) such that \\(u_\\ell&gt;0\\) and \\(\\dfrac{\\text{row }\\ell}{u_\\ell} \\prec \\dfrac{\\text{row }i}{u_i}\\) for every \\(i\\ne \\ell\\) with \\(u_i&gt;0\\). (3.5)</p> <p>Key box \u2014 Meaning</p> <p>It is the ratio test plus a deterministic tie-break: \u201cpick the lexicographically smallest normalized row.\u201d</p>"},{"location":"chapter3/notes/#344-example-37-how-tie-breaking-works","title":"3.4.4 Example 3.7 (how tie-breaking works)","text":"<p>Key box \u2014 Ratio tie</p> <p>Suppose \\(j=3\\) and two rows tie: \\(\\dfrac{x_{B(1)}}{u_1}=\\dfrac{1}{3}\\) and \\(\\dfrac{x_{B(3)}}{u_3}=\\dfrac{3}{9}=\\dfrac{1}{3}\\). Divide each candidate row by its pivot entry and compare normalized rows lexicographically.</p> <p>Key box \u2014 Uniqueness point used in the book</p> <p>Under the assumption that rows of \\(A\\) are linearly independent, this rule yields a unique leaving row; identical normalized rows would contradict \\(\\mathrm{rank}(A)=m\\).</p>"},{"location":"chapter3/notes/#345-why-lexicographic-pivoting-prevents-cycling-main-idea","title":"3.4.5 Why lexicographic pivoting prevents cycling (main idea)","text":"<p>Key box \u2014 Three-step proof structure</p> <ol> <li>Constraint rows that start lexicographically positive stay lexicographically positive under pivots.  </li> <li>The objective (zeroth) row increases lexicographically at each pivot.  </li> <li>Therefore, the tableau (hence the basis) cannot repeat \\(\\Rightarrow\\) no cycling.</li> </ol>"},{"location":"chapter3/notes/#346-blands-rule-smallest-subscript-pivoting","title":"3.4.6 Bland\u2019s rule (smallest-subscript pivoting)","text":"<p>Definition box \u2014 Bland\u2019s rule</p> <ul> <li>Entering: among eligible entering variables (minimization: \\(\\bar c_j&lt;0\\)), choose the smallest index \\(j\\).  </li> <li>Leaving: do the ratio test; among ties, choose the leaving basic variable with smallest index.</li> </ul> <p>Theorem box \u2014 Bland</p> <p>If Bland\u2019s rule is used, the simplex method cannot cycle and must terminate in finitely many pivots.</p> <p>Practical box</p> <p>Bland\u2019s rule is simple to implement in revised simplex, and is often used as a safe fallback when degeneracy causes stalling.</p>"},{"location":"chapter3/notes/#347-practical-notes","title":"3.4.7 Practical notes","text":"<p>Key box</p> <ul> <li>Lexicographic pivoting is easiest in a full tableau (explicit rows).  </li> <li>Bland\u2019s rule is the simplest \u201calways safe\u201d anticycling rule in revised simplex implementations.</li> </ul>"},{"location":"chapter3/notes/#35-finding-an-initial-basic-feasible-solution-initial-bfs","title":"3.5 Finding an initial basic feasible solution (initial BFS)","text":""},{"location":"chapter3/notes/#351-the-problem-simplex-needs-a-starting-bfs","title":"3.5.1 The problem: simplex needs a starting BFS","text":"<p>Key box \u2014 Why Phase I exists</p> <p>Simplex needs an initial BFS: - pick invertible basis \\(B\\), - set \\(x_N=0\\), - compute \\(x_B=B^{-1}b\\), - require \\(x_B\\ge 0\\).</p> <p>Sometimes this BFS is obvious; often it is not.</p>"},{"location":"chapter3/notes/#352-easy-case-inequalities-with-nonnegative-right-hand-side","title":"3.5.2 Easy case: inequalities with nonnegative right-hand side","text":"<p>Key box \u2014 Slack variable start</p> <p>If constraints are \\(Ax\\le b\\) with \\(b\\ge 0\\), introduce slack \\(s\\ge 0\\) so \\(Ax+s=b\\). Then \\(x=0,\\ s=b\\) is feasible and gives an obvious BFS (slack columns form the identity).</p>"},{"location":"chapter3/notes/#353-general-case-use-an-auxiliary-phase-i-problem","title":"3.5.3 General case: use an auxiliary (Phase I) problem","text":"<p>Assumption box</p> <p>After possibly multiplying some equalities by \\(-1\\), assume \\(b\\ge 0\\).</p> <p>Definition box \u2014 Phase I auxiliary LP</p> <p>Introduce artificial variables \\(y\\in\\mathbb{R}^m\\) with \\(y\\ge 0\\) and solve: \\(\\min\\ \\sum_{i=1}^m y_i \\ \\text{s.t.}\\ Ax+y=b,\\ x\\ge 0,\\ y\\ge 0\\).  (Phase I)</p> <p>Theorem box \u2014 Phase I correctness (core logic)</p> <ol> <li>Phase I always has an easy BFS: \\(x=0,\\ y=b\\).  </li> <li>If the original LP is feasible, Phase I optimum is \\(0\\) (because \\((x,0)\\) is feasible).  </li> <li>If Phase I optimum is \\(&gt;0\\), the original LP is infeasible.</li> </ol> <p>Key box \u2014 What Phase I returns</p> <p>If the optimal Phase I value is \\(0\\), it produces a feasible basis for the original constraints (after removing artificial basics if needed).</p>"},{"location":"chapter3/notes/#354-the-two-phase-simplex-method-algorithm-form","title":"3.5.4 The two-phase simplex method (algorithm form)","text":"<p>Key box \u2014 Two-phase simplex</p> <p>Phase I 1. Ensure \\(b\\ge 0\\) by sign flips. 2. Add \\(y\\ge 0\\) and solve Phase I. 3. If optimum \\(&gt;0\\): original LP infeasible. 4. If optimum \\(=0\\): we have a feasible solution with \\(y=0\\).    - If no artificial variable is basic: drop \\(y\\) and start Phase II.    - If some artificial variable is still basic (value \\(0\\)): clean up (Step 5). 5. Drive artificials out or drop redundant constraints (row is zero in original columns).</p> <p>Phase II 1. Use the Phase I final basis (with only \\(A\\)-columns) as the starting basis. 2. Recompute reduced costs for the original \\(c\\). 3. Run simplex on the original objective.</p>"},{"location":"chapter3/notes/#355-a-complete-worked-example-two-phase-full-tableau-style","title":"3.5.5 A complete worked example (two-phase, full tableau style)","text":"<p>Example box \u2014 Original LP</p> <p>\\(\\min\\ z=x_1+2x_2\\) subject to \\(x_1-x_2=1\\), \\(x_1+x_2+x_3=3\\), \\(x_1,x_2,x_3\\ge 0\\).</p> <p>Example box \u2014 Phase I formulation</p> <p>Add artificials \\(y_1,y_2\\ge 0\\): \\(x_1-x_2+y_1=1\\), \\(x_1+x_2+x_3+y_2=3\\), and minimize \\(w=y_1+y_2\\).</p> <p>Example box \u2014 Key conclusion</p> <p>Phase I ends with \\(w^*=0\\) and (example endpoint shown earlier) \\((x_1,x_2,x_3,y_1,y_2)=(2,1,0,0,0)\\). Then Phase II (dropping \\(y\\)) yields \\((x_1,x_2,x_3)=(1,0,2)\\) and \\(z^*=1\\).</p> <p>Key box \u2014 What to remember</p> <ul> <li>Phase I: only feasibility (\\(y\\to 0\\)).  </li> <li>Phase II: optimize the original cost starting from a feasible basis.</li> </ul>"},{"location":"chapter3/notes/#356-the-big-m-method-single-phase-alternative","title":"3.5.6 The big-\\(M\\) method (single-phase alternative)","text":"<p>Definition box \u2014 Big-\\(M\\)</p> <p>Solve one LP: \\(\\min\\ \\sum_{j=1}^n c_jx_j + M\\sum_{i=1}^m y_i\\) s.t. \\(Ax+y=b,\\ x\\ge 0,\\ y\\ge 0\\), with \\(M\\) \u201cvery large\u201d.</p> <p>Key box \u2014 Numerical note</p> <p>Using a huge numeric \\(M\\) can cause numerical trouble in floating point arithmetic; two-phase is typically preferred in practice.</p>"},{"location":"chapter3/notes/#357-comparison-two-phase-vs-big-m","title":"3.5.7 Comparison: two-phase vs big-\\(M\\)","text":"<p>Key box</p> <ul> <li>Two-phase: clean separation, standard in solvers, numerically stable.  </li> <li>Big-\\(M\\): one phase conceptually, but can be numerically delicate unless \\(M\\) is treated symbolically (textbook device).</li> </ul>"},{"location":"chapter3/notes/#36-the-geometry-of-the-simplex-method-column-geometry","title":"3.6 The geometry of the simplex method (column geometry)","text":"<p>Key box \u2014 Why this section exists</p> <p>This section explains geometrically: 1) what a basis means, and 2) why reduced costs select entering variables.</p>"},{"location":"chapter3/notes/#361-add-a-convexity-constraint","title":"3.6.1 Add a convexity constraint","text":"<p>Definition box \u2014 Convexity constraint</p> <p>Add \\(e^\\top x=1\\) so that \\(x\\) becomes convex-combination weights.</p> <p>Key box \u2014 The lifted formulation used in the book</p> <p>Consider \\(\\min\\ c^\\top x\\) s.t. \\(Ax=b,\\ e^\\top x=1,\\ x\\ge 0\\). (3.6) Define the scalar \\(z=c^\\top x\\).</p>"},{"location":"chapter3/notes/#362-lift-the-columns-into-one-higher-dimension","title":"3.6.2 Lift the columns into one higher dimension","text":"<p>Key box \u2014 Convex hull picture</p> <p>Because \\(x\\ge 0\\) and \\(\\sum_i x_i=1\\), we have \\(Ax=\\sum_{i=1}^n x_iA_i=b\\), so \\(b\\) is a convex combination of the columns \\(A_i\\). Also \\(z=c^\\top x=\\sum_{i=1}^n x_ic_i\\). Therefore \\((b,z)\\) is a convex combination of the lifted points \\((A_i,c_i)\\in\\mathbb{R}^{m+1}\\).</p>"},{"location":"chapter3/notes/#363-requirement-line-and-feasibility","title":"3.6.3 Requirement line and feasibility","text":"<p>Definition box \u2014 Requirement line</p> <p>The requirement line is the vertical line above \\(b\\): \\(\\{(b,z)\\mid z\\in\\mathbb{R}\\}\\).</p> <p>Key box \u2014 Feasibility and optimality in the picture</p> <p>Let \\(H=\\mathrm{conv}\\{(A_1,c_1),\\dots,(A_n,c_n)\\}\\). - Feasible \\(\\Longleftrightarrow\\) requirement line intersects \\(H\\). - Optimal solution corresponds to the lowest intersection point (smallest \\(z\\)).</p>"},{"location":"chapter3/notes/#364-affine-independence-and-simplices-definition-36","title":"3.6.4 Affine independence and simplices (Definition 3.6)","text":"<p>Definition box \u2014 Affine independence</p> <p>Points \\(y^1,\\dots,y^{k+1}\\in\\mathbb{R}^n\\) are affinely independent if \\(y^1-y^{k+1},\\ y^2-y^{k+1},\\ \\dots,\\ y^k-y^{k+1}\\) are linearly independent.</p> <p>Definition box \u2014 Simplex</p> <p>The convex hull of \\(k+1\\) affinely independent points is a \\(k\\)-dimensional simplex (segment, triangle, tetrahedron, \u2026).</p>"},{"location":"chapter3/notes/#365-bfs-and-the-basic-simplex","title":"3.6.5 BFS and the \u201cbasic simplex\u201d","text":"<p>Key box \u2014 Why \\(m+1\\) basic variables here</p> <p>With constraints \\(Ax=b\\) (gives \\(m\\) equations) and \\(e^\\top x=1\\) (one more), there are \\(m+1\\) equalities. A BFS corresponds to selecting \\(m+1\\) basic variables (i.e., \\(m+1\\) lifted points).</p> <p>Key box \u2014 Geometry</p> <p>The lifted basic points form an \\(m\\)-dimensional simplex (the basic simplex). The current point \\((b,z)\\) is a convex combination of those basic points.</p>"},{"location":"chapter3/notes/#366-change-of-basis-move-to-an-adjacent-simplex","title":"3.6.6 Change of basis = move to an adjacent simplex","text":"<p>Key box</p> <p>One pivot replaces one basic point by one nonbasic point. Geometrically, simplex walks from one basic simplex to an adjacent one along the boundary of \\(H\\).</p>"},{"location":"chapter3/notes/#367-dual-plane-and-reduced-costs-key-link","title":"3.6.7 Dual plane and reduced costs (key link)","text":"<p>Definition box \u2014 Dual plane</p> <p>The lifted basic points lie on an \\(m\\)-dimensional hyperplane in \\(\\mathbb{R}^{m+1}\\) called the dual plane.</p> <p>Theorem box \u2014 Reduced cost = below/above dual plane (minimization)</p> <p>For a nonbasic index \\(j\\): - \\((A_j,c_j)\\) lies below the current dual plane \\(\\Longleftrightarrow\\ \\bar c_j&lt;0\\), - \\((A_j,c_j)\\) lies above the dual plane \\(\\Longleftrightarrow\\ \\bar c_j&gt;0\\).</p> <p>Key box \u2014 Meaning</p> <p>Reduced cost is a signed vertical distance from the dual plane to the lifted point.</p>"},{"location":"chapter3/notes/#368-pivoting-as-hinging-physical-analogy","title":"3.6.8 Pivoting as \u201chinging\u201d (physical analogy)","text":"<p>Key box</p> <p>Think of the basic simplex as a rigid face. Pivoting \u201chinges\u201d to a neighboring face; the intersection with the requirement line moves up/down. A profitable pivot moves the intersection down (decreases \\(z\\)).</p>"},{"location":"chapter3/notes/#369-example-310-why-simplex-can-be-fast","title":"3.6.9 Example 3.10 (why simplex can be fast)","text":"<p>Key box</p> <p>For \\(m=1\\), the picture is 2D and simplex can reach the optimal basis in very few pivots even when \\(n\\) is large.</p>"},{"location":"chapter3/notes/#37-computational-efficiency-of-the-simplex-method","title":"3.7 Computational efficiency of the simplex method","text":"<p>Key box \u2014 Two drivers of runtime</p> <p>Simplex effort depends on: 1) work per iteration, and 2) number of iterations (pivots).</p>"},{"location":"chapter3/notes/#371-work-per-iteration-recap","title":"3.7.1 Work per iteration (recap)","text":"<p>Key box</p> <ul> <li>Full tableau: \\(\\mathcal{O}(mn)\\) arithmetic per pivot (update an \\(m\\times n\\) tableau).  </li> <li>Revised simplex: basis solves/updates about \\(\\mathcal{O}(m^2)\\) per pivot, with reduced-cost computation depending on pricing/sparsity.</li> </ul>"},{"location":"chapter3/notes/#372-worst-case-number-of-iterations-can-be-exponential","title":"3.7.2 Worst-case number of iterations can be exponential","text":"<p>Theorem box \u2014 Exponential worst-case (Theorem 3.3)</p> <p>There exist LP families where simplex (under some pivot rules) requires \\(2^n-1\\) pivots: - feasible set has \\(2^n\\) vertices, - simplex can be forced to visit almost all vertices before terminating.</p> <p>Key box \u2014 Construction idea</p> <p>Start from the unit cube \\(0\\le x_i\\le 1\\) and perturb it with constraints like \\(\\varepsilon\\le x_1\\le 1\\), \\(\\varepsilon x_{i-1}\\le x_i \\le 1-\\varepsilon x_{i-1}\\) for \\(i=2,\\dots,n\\), so the objective decreases along a long edge-walk path.</p>"},{"location":"chapter3/notes/#373-diameter-of-polyhedra-and-the-hirsch-conjecture","title":"3.7.3 Diameter of polyhedra and the Hirsch conjecture","text":"<p>Definition box \u2014 Diameter of a polyhedron</p> <p>Vertices \\(x,y\\) are adjacent if connected by an edge. Let \\(d(x,y)\\) be the minimum number of edges in a path from \\(x\\) to \\(y\\). The diameter is \\(D(P)=\\max_{x,y\\text{ vertices}} d(x,y)\\).</p> <p>Key box \u2014 \\(\\Delta(n,m)\\) and Hirsch</p> <p>Let \\(\\Delta(n,m)\\) be the maximum diameter over bounded polyhedra in \\(\\mathbb{R}^n\\) described by \\(m\\) inequalities. Hirsch conjectured \\(\\Delta(n,m)\\le m-n\\). (The book discusses related results and bounds, especially differences between bounded and unbounded cases.)</p>"},{"location":"chapter3/notes/#374-average-case-behavior-why-practice-looks-good","title":"3.7.4 Average-case behavior (why practice looks good)","text":"<p>Key box</p> <p>Worst-case does not predict typical performance. Average-case claims depend on the probability model for \u201crandom LP,\u201d but many models suggest simplex often needs a modest number of pivots in practice.</p>"},{"location":"chapter3/notes/#38-summary-what-to-memorize-for-exams","title":"3.8 Summary (what to memorize for exams)","text":"<p>Key box \u2014 Big picture</p> <ul> <li>\\(P=\\{x\\mid Ax=b,\\ x\\ge 0\\}\\) is a polyhedron.  </li> <li>Simplex moves among BFSs (vertices/extreme points) along edges.  </li> <li>Each pivot changes one entering nonbasic variable and one leaving basic variable.</li> </ul>"},{"location":"chapter3/notes/#382-core-mathematical-ingredients","title":"3.8.2 Core mathematical ingredients","text":"<p>Key box \u2014 Reduced costs</p> <p>For basis \\(B\\): \\(\\bar c_j = c_j - c_B^\\top B^{-1}A_j\\). - If \\(\\bar c_j\\ge 0\\) for all nonbasic \\(j\\), the BFS is optimal. - If BFS is nondegenerate and some \\(\\bar c_j&lt;0\\), there is a feasible improving edge.</p> <p>Key box \u2014 Ratio test</p> <p>For entering index \\(j\\), the step size is \\(\\theta^*=\\min_{i:(B^{-1}A_j)_i&gt;0}\\dfrac{(x_B)_i}{(B^{-1}A_j)_i}\\). - Leaving variable is the minimizer. - If no component of \\(B^{-1}A_j\\) is positive, the objective is unbounded below (\\(-\\infty\\)).</p>"},{"location":"chapter3/notes/#383-implementation-styles-section-33","title":"3.8.3 Implementation styles (Section 3.3)","text":"<p>Key box</p> <ol> <li>Naive: explicitly form \\(B^{-1}\\) each iteration (educational).  </li> <li>Revised simplex: solve systems with \\(B\\) / \\(B^\\top\\) for \\(x_B\\), multipliers, reduced costs.  </li> <li>Full tableau: maintain \\(B^{-1}A\\) and \\(B^{-1}b\\) and update by row operations.</li> </ol>"},{"location":"chapter3/notes/#384-degeneracy-cycling-and-anticycling","title":"3.8.4 Degeneracy, cycling, and anticycling","text":"<p>Key box</p> <p>Degeneracy can cause \\(\\theta^*=0\\) pivots and cycling. Anticycling rules: - lexicographic pivoting, - Bland\u2019s rule, guarantee termination (no basis repetition).</p>"},{"location":"chapter3/notes/#385-how-to-start-initial-bfs","title":"3.8.5 How to start: initial BFS","text":"<p>Key box \u2014 Phase I</p> <p>If no obvious BFS exists, use Phase I: \\(\\min\\ \\sum_{i=1}^m y_i \\ \\text{s.t.}\\ Ax+y=b,\\ x\\ge 0,\\ y\\ge 0\\). - optimum \\(&gt;0\\) \\(\\Rightarrow\\) infeasible original LP - optimum \\(=0\\) \\(\\Rightarrow\\) feasible and provides a starting basis for Phase II</p>"},{"location":"chapter3/notes/#386-geometry-intuition","title":"3.8.6 Geometry intuition","text":"<p>Key box</p> <p>With \\(e^\\top x=1\\), feasibility/optimality can be read from intersections of the requirement line with the convex hull of lifted points \\((A_i,c_i)\\), and reduced costs correspond to whether a point lies below the current dual plane.</p>"},{"location":"chapter3/notes/#387-efficiency-story","title":"3.8.7 Efficiency story","text":"<p>Key box</p> <ul> <li>Per-iteration work is controlled by tableau vs revised simplex and sparsity.  </li> <li>Pivot count can be exponential in worst case, but is often small in practice.</li> </ul>"},{"location":"chapter4/","title":"Chapter 2","text":""},{"location":"chapter4/#notes","title":"Notes","text":"<ul> <li>Notes</li> </ul>"},{"location":"chapter4/#doubts","title":"Doubts","text":"<ul> <li>Doubts</li> </ul>"},{"location":"chapter4/notes/","title":"Notes","text":""},{"location":"chapter4/notes/#41-motivation","title":"4.1 Motivation","text":"<p>Duality theory can be motivated as an extension of the Lagrange multiplier idea from calculus: instead of enforcing a constraint \u201chard,\u201d we allow it to be violated but assign a price/penalty to the violation. In LP, the \u201cright prices\u201d end up being found by solving a new LP (the dual).</p>"},{"location":"chapter4/notes/#411-a-warm-up-lagrange-multiplier-idea-calculus-analogy","title":"4.1.1 A warm-up: Lagrange multiplier idea (calculus analogy)","text":"<p>Key box \u2014 The core idea behind Lagrange multipliers</p> <p>Instead of enforcing a hard equality constraint exactly, we: - allow the constraint to be violated, and - introduce a price (multiplier) for the amount of violation, so the constrained problem is replaced by an unconstrained penalized problem.</p> <p>Example (as in the text)</p> <p>Minimize \\(x^2+y^2\\) subject to \\(x+y=1\\). Introduce multiplier \\(p\\) and define the Lagrangian \\(L(x,y,p)=x^2+y^2+p(1-x-y)\\).</p> <p>Computation box \u2014 Minimizing \\(L\\) over \\((x,y)\\) for fixed \\(p\\)</p> <p>For fixed \\(p\\), minimize w.r.t. \\(x,y\\) by setting derivatives to zero: - \\(\\partial L/\\partial x = 2x - p = 0 \\Rightarrow x=p/2\\) - \\(\\partial L/\\partial y = 2y - p = 0 \\Rightarrow y=p/2\\)</p> <p>Enforcing the original constraint \\(x+y=1\\) gives \\(p/2+p/2=1 \\Rightarrow p=1\\), hence \\(x=y=1/2\\).</p> <p>Intuition box</p> <p>When the \u201cprice\u201d \\(p\\) is chosen correctly (here \\(p=1\\)), the solution that minimizes the penalized problem also satisfies the hard constraint, so the hard constraint becomes \u201cirrelevant\u201d at the optimum.</p>"},{"location":"chapter4/notes/#412-doing-the-same-thing-in-linear-programming","title":"4.1.2 Doing the same thing in linear programming","text":"<p>We consider the standard form primal LP:</p> <ul> <li>minimize \\(c^\\top x\\)</li> <li>subject to \\(Ax=b\\), \\(x\\ge 0\\)</li> </ul> <p>Assume an optimal solution \\(x^\\*\\) exists.</p> <p>Definition box \u2014 Relaxed (penalized) problem and the function \\(g(p)\\)</p> <p>Introduce a price vector \\(p\\in\\mathbb{R}^m\\) and relax the equality \\(Ax=b\\) by penalizing violation: - relaxed problem: minimize \\(c^\\top x + p^\\top(b-Ax)\\) subject to \\(x\\ge 0\\) - define \\(g(p)\\) = optimal value of the relaxed problem:   \\(g(p)=\\min_{x\\ge 0}\\big[c^\\top x + p^\\top(b-Ax)\\big]\\)</p> <p>Key box \u2014 Why \\(g(p)\\) is always a lower bound on the primal optimum</p> <p>The relaxed problem allows more freedom than the original primal (because we don\u2019t force \\(Ax=b\\); we only penalize violation). Take the primal optimal solution \\(x^\\*\\) (feasible, so \\(Ax^\\*=b\\)): - \\(g(p) \\le c^\\top x^\\* + p^\\top(b-Ax^\\*) = c^\\top x^\\*\\)</p> <p>So for every \\(p\\), \\(g(p)\\) gives a lower bound on the optimal primal cost.</p>"},{"location":"chapter4/notes/#413-dual-as-best-possible-lower-bound","title":"4.1.3 Dual as \u201cbest possible lower bound\u201d","text":"<p>Key box \u2014 Dual problem = tightest lower bound of this form</p> <p>Since every \\(p\\) gives a lower bound \\(g(p)\\le c^\\top x^\\*\\), it is natural to search for the tightest such bound: - maximize \\(g(p)\\) over all \\(p\\)</p> <p>This maximization problem is what becomes the dual.</p>"},{"location":"chapter4/notes/#414-compute-gp-and-see-the-dual-constraints-appear","title":"4.1.4 Compute \\(g(p)\\) and see the dual constraints appear","text":"<p>Start from the definition: - \\(g(p)=\\min_{x\\ge 0}\\big[c^\\top x + p^\\top(b-Ax)\\big]\\)</p> <p>Rewrite: - \\(g(p)=\\min_{x\\ge 0}\\big[p^\\top b + (c^\\top - p^\\top A)x\\big]\\) - \\(g(p)=p^\\top b + \\min_{x\\ge 0}(c^\\top - p^\\top A)x\\)</p> <p>Key box \u2014 The crucial minimization fact</p> <p>Consider \\(\\min_{x\\ge 0}(c^\\top - p^\\top A)x\\).</p> <ul> <li>If \\(c^\\top - p^\\top A \\ge 0^\\top\\) (componentwise), the minimum is achieved at \\(x=0\\), so the minimum equals \\(0\\).</li> <li>If any component of \\(c^\\top - p^\\top A\\) is negative, we can drive the objective to \\(-\\infty\\) by increasing the corresponding \\(x_j\\), so the minimum is \\(-\\infty\\).</li> </ul> <p>So: - \\(g(p)=p^\\top b\\) if \\(p^\\top A \\le c^\\top\\) - \\(g(p)=-\\infty\\) otherwise</p> <p>Conclusion box \u2014 Dual problem for standard form</p> <p>To maximize \\(g(p)\\), we only consider \\(p\\) that make \\(g(p)\\) finite, i.e. those satisfying \\(p^\\top A \\le c^\\top\\). Therefore, the dual is:</p> <ul> <li>maximize \\(p^\\top b\\)</li> <li>subject to \\(p^\\top A \\le c^\\top\\)</li> </ul>"},{"location":"chapter4/notes/#415-where-sign-restrictions-come-from-preview-of-the-general-dual","title":"4.1.5 Where sign restrictions come from (preview of the general dual)","text":"<p>The standard form example had equality constraints \\(Ax=b\\), and we ended up with no sign restriction on \\(p\\) (i.e., \u201c\\(p\\) free\u201d). Different primal constraint types produce different sign restrictions and dual constraint directions.</p> <p>Key box \u2014 Inequalities in the primal create sign restrictions in the dual (idea)</p> <p>If the primal had constraints \\(Ax\\ge b\\), we can rewrite them as equalities using surplus variables: - \\(Ax - s = b\\) with \\(s\\ge 0\\)</p> <p>When you dualize that standard-form version, the nonnegativity of \\(s\\) forces the corresponding dual condition that the associated prices satisfy \\(p\\ge 0\\).</p> <p>Key box \u2014 Free variables in the primal create equalities in the dual (idea)</p> <p>If a primal variable is free (unrestricted sign), it can be written as a difference of two nonnegative variables: - \\(x = x^+ - x^-\\) with \\(x^+\\ge 0,\\;x^-\\ge 0\\)</p> <p>This \u201csplitting\u201d is the algebraic reason dual constraints may become equalities (you effectively get two inequalities that must both hold, hence equality).</p>"},{"location":"chapter4/notes/#42-the-dual-problem","title":"4.2 The dual problem","text":"<p>In Section 4.1 we built intuition: for a primal minimization problem, every choice of prices (dual variables) gives a lower bound on the primal optimal cost, and the dual problem maximizes this bound. In this section we define the dual for a general LP (with mixed constraint directions and mixed variable sign restrictions).</p>"},{"location":"chapter4/notes/#421-general-primaldual-definition-most-general-form","title":"4.2.1 General primal\u2013dual definition (most general form)","text":"<p>Definition box \u2014 General primal (minimization form)</p> <p>Let \\(A\\) be a matrix with rows \\(a_i^\\top\\) and columns \\(A_j\\). Partition the constraint indices into \\(M_1, M_2, M_3\\) and the variable indices into \\(N_1, N_2, N_3\\).</p> <p>The primal problem is: - minimize \\(c^\\top x\\) - subject to   - \\(a_i^\\top x \\ge b_i,\\ \\ i\\in M_1\\)   - \\(a_i^\\top x \\le b_i,\\ \\ i\\in M_2\\)   - \\(a_i^\\top x = b_i,\\ \\ i\\in M_3\\)   - \\(x_j \\ge 0,\\ \\ j\\in N_1\\)   - \\(x_j \\le 0,\\ \\ j\\in N_2\\)   - \\(x_j\\) free,\\ \\ \\(j\\in N_3\\)</p> <p>Definition box \u2014 Dual associated with the above primal</p> <p>Introduce dual variables \\(p_i\\) for primal constraints \\(i\\in M_1\\cup M_2\\cup M_3\\). The dual problem is: - maximize \\(p^\\top b\\) - subject to   - \\(p_i \\ge 0,\\ \\ i\\in M_1\\)   - \\(p_i \\le 0,\\ \\ i\\in M_2\\)   - \\(p_i\\) free,\\ \\ \\(i\\in M_3\\)   - \\(p^\\top A_j \\le c_j,\\ \\ j\\in N_1\\)   - \\(p^\\top A_j \\ge c_j,\\ \\ j\\in N_2\\)   - \\(p^\\top A_j = c_j,\\ \\ j\\in N_3\\)</p> <p>Key box \u2014 Constraint/variable \u201cswap\u201d principle</p> <ul> <li>Each primal constraint (other than sign constraints on variables) produces a dual variable.  </li> <li>Each primal variable produces a dual constraint.  </li> <li>The direction/equality and sign restrictions determine whether the dual side is \\(\\ge 0\\), \\(\\le 0\\), free, or \\(\\le/\\ge/=\\).</li> </ul>"},{"location":"chapter4/notes/#422-table-41-mechanical-rules-primal-min-dual-max","title":"4.2.2 Table 4.1: mechanical rules (primal min \u2194 dual max)","text":"<p>Key box \u2014 Table 4.1 (rules you should memorize)</p> <p>Primal constraints \\(\\longrightarrow\\) Dual variable sign (dual is a maximization problem)</p> Primal constraint type Dual variable sign \\(\\ge b_i\\) \\(p_i \\ge 0\\) \\(\\le b_i\\) \\(p_i \\le 0\\) \\(= b_i\\) \\(p_i\\) free <p>Primal variable sign \\(\\longrightarrow\\) Dual constraint type</p> Primal variable type Dual constraint on \\(p^\\top A_j\\) \\(x_j \\ge 0\\) \\(p^\\top A_j \\le c_j\\) \\(x_j \\le 0\\) \\(p^\\top A_j \\ge c_j\\) \\(x_j\\) free \\(p^\\top A_j = c_j\\) <p>Convention box</p> <p>If we start with a maximization primal, we can convert it to an equivalent minimization problem and then apply the rules above. To avoid confusion, we will adhere to the convention: primal = minimization, dual = maximization.</p>"},{"location":"chapter4/notes/#423-compact-matrix-pairs-common-special-cases","title":"4.2.3 Compact matrix pairs (common special cases)","text":"<p>Key box \u2014 Standard form (equalities + nonnegativity)</p> <p>Primal: - minimize \\(c^\\top x\\) - subject to \\(Ax=b\\), \\(x\\ge 0\\)</p> <p>Dual: - maximize \\(p^\\top b\\) - subject to \\(p^\\top A \\le c^\\top\\)   (equivalently \\(A^\\top p \\le c\\))</p> <p>Key box \u2014 Inequalities \\(Ax\\ge b\\) (no explicit sign constraint on \\(x\\) shown here)</p> <p>Primal: - minimize \\(c^\\top x\\) - subject to \\(Ax\\ge b\\)</p> <p>Dual: - maximize \\(p^\\top b\\) - subject to \\(p^\\top A = c^\\top\\), \\(p\\ge 0\\)</p> <p>Intuition box</p> <ul> <li>A free primal variable forces an equality in the dual.  </li> <li>A primal constraint of type \\(\\ge\\) forces a nonnegative dual variable (prices cannot be negative when the constraint is of \u201cat least\u201d type).</li> </ul>"},{"location":"chapter4/notes/#424-example-41-the-dual-of-the-dual-is-the-primal","title":"4.2.4 Example 4.1: the dual of the dual is the primal","text":"<p>Example box \u2014 Form the dual using Table 4.1</p> <p>Primal (given): minimize \\(x_1 + 2x_2 + 3x_3\\) subject to - \\(-x_1 + 3x_2 = 5\\) - \\(2x_1 - x_2 + 3x_3 \\ge 6\\) - \\(x_3 \\le 4\\) - \\(x_1 \\ge 0,\\ \\ x_2 \\le 0,\\ \\ x_3\\) free</p> <p>Dual (by the rules): maximize \\(5p_1 + 6p_2 + 4p_3\\) subject to - \\(p_1\\) free (because the first primal constraint is an equality) - \\(p_2 \\ge 0\\) (because the second primal constraint is \\(\\ge\\)) - \\(p_3 \\le 0\\) (because the third primal constraint is \\(\\le\\)) - \\(-p_1 + 2p_2 \\le 1\\) (because \\(x_1\\ge 0\\)) - \\(3p_1 - p_2 \\ge 2\\) (because \\(x_2\\le 0\\)) - \\(3p_2 + p_3 = 3\\) (because \\(x_3\\) is free)</p> <p>Key box \u2014 Converting the dual back into the primal</p> <p>If we: 1) transform the dual into an equivalent minimization problem, 2) and then form its dual, we obtain a problem equivalent to the original primal.</p> <p>(This is illustrated in the text by explicitly dualizing twice and observing that the resulting problem matches the original primal up to trivial sign/format changes.)</p>"},{"location":"chapter4/notes/#425-theorem-41-dual-of-the-dual","title":"4.2.5 Theorem 4.1 (dual of the dual)","text":"<p>Theorem box \u2014 The dual of the dual is the primal</p> <p>If we transform the dual into an equivalent minimization problem and then form its dual, we obtain a problem equivalent to the original primal problem.</p> <p>Remark box \u2014 Equivalent primal forms lead to equivalent duals</p> <p>A linear program can be rewritten in many equivalent ways (e.g., add slack/surplus variables; replace a free variable by the difference of two nonnegative variables). These different\u2014but equivalent\u2014primal forms may yield different-looking duals, but the resulting dual problems are equivalent.</p>"},{"location":"chapter4/notes/#43-the-duality-theorem","title":"4.3 The duality theorem","text":""},{"location":"chapter4/notes/#431-a-useful-decomposition-u_i-and-v_j","title":"4.3.1 A useful decomposition: \\(U_i\\) and \\(V_j\\)","text":"<p>Definition box \u2014 The quantities \\(U_i\\) and \\(V_j\\)</p> <p>For any vectors \\(x\\) and \\(p\\), define - \\(U_i = p_i\\,(a_i^\\top x - b_i)\\)  (one term per primal constraint) - \\(V_j = (c_j - p^\\top A_j)\\,x_j\\) (one term per primal variable)</p> <p>Key box \u2014 Why \\(U_i\\ge 0\\) and \\(V_j\\ge 0\\) under feasibility</p> <p>If \\(x\\) is primal feasible and \\(p\\) is dual feasible, then:</p> <ul> <li> <p>For each constraint \\(i\\), dual feasibility forces the sign of \\(p_i\\) to match the direction of the primal constraint, so \\(p_i(a_i^\\top x - b_i)\\ge 0\\). Hence \\(U_i\\ge 0\\).</p> </li> <li> <p>For each variable \\(j\\), primal feasibility forces the sign restriction on \\(x_j\\) (e.g., \\(x_j\\ge 0\\), \\(x_j\\le 0\\), or free), and dual feasibility forces the matching inequality or equality on \\(p^\\top A_j\\) relative to \\(c_j\\). Together they imply \\((c_j - p^\\top A_j)x_j\\ge 0\\). Hence \\(V_j\\ge 0\\).</p> </li> </ul> <p>Key box \u2014 Identity behind weak duality</p> <p>Expand the sums:</p> <ul> <li>\\(\\sum_i U_i = \\sum_i p_i(a_i^\\top x - b_i) = p^\\top A x - p^\\top b\\) </li> <li>\\(\\sum_j V_j = \\sum_j (c_j - p^\\top A_j)x_j = c^\\top x - p^\\top A x\\)</li> </ul> <p>Adding them gives \\(c^\\top x - p^\\top b = \\sum_i U_i + \\sum_j V_j \\ge 0\\).</p>"},{"location":"chapter4/notes/#432-weak-duality","title":"4.3.2 Weak duality","text":"<p>Theorem box \u2014 Weak duality</p> <p>For any primal feasible \\(x\\) and any dual feasible \\(p\\), we have \\(p^\\top b \\le c^\\top x\\).  </p> <p>Therefore, every dual feasible solution provides a lower bound on the optimal primal value (for a minimization primal).</p> <p>Intuition box</p> <p>The gap \\(c^\\top x - p^\\top b\\) splits into constraint-violation terms \\(U_i\\) and reduced-cost-like terms \\(V_j\\), each of which is \\(\\ge 0\\) under feasibility.</p>"},{"location":"chapter4/notes/#433-corollaries-of-weak-duality","title":"4.3.3 Corollaries of weak duality","text":"<p>Corollary box \u2014 Unboundedness implies infeasibility on the other side</p> <ul> <li>If the primal (minimization) problem is unbounded (optimal value \\(=-\\infty\\)), then the dual must be infeasible.  </li> <li>If the dual (maximization) problem is unbounded (optimal value \\(=+\\infty\\)), then the primal must be infeasible.</li> </ul> <p>Corollary box \u2014 Equal costs certify optimality</p> <p>Suppose \\(x\\) is primal feasible and \\(p\\) is dual feasible, and \\(c^\\top x = p^\\top b\\). Then \\(x\\) is optimal for the primal and \\(p\\) is optimal for the dual.</p> <p>Reason: for any primal feasible \\(y\\), weak duality gives \\(p^\\top b \\le c^\\top y\\). If \\(p^\\top b = c^\\top x\\), then \\(c^\\top x \\le c^\\top y\\) for all feasible \\(y\\), so \\(x\\) is optimal. A symmetric argument gives optimality of \\(p\\).</p>"},{"location":"chapter4/notes/#434-strong-duality-the-duality-theorem","title":"4.3.4 Strong duality (the duality theorem)","text":"<p>Theorem box \u2014 Strong duality</p> <p>Under the standard assumptions (feasibility and existence of an optimal solution), the primal and dual optimal values are equal. In particular, there exist optimal solutions \\(x^*\\) and \\(p^*\\) such that \\(c^\\top x^* = (p^*)^\\top b\\).</p> <p>Proof idea box \u2014 Prove in standard form via simplex, then extend</p> <p>The book\u2019s approach is:</p> <p>1) Prove strong duality for a standard-form problem (with independent rows) using simplex. 2) Reduce a general LP to an equivalent standard-form LP and use equivalence of duals.</p>"},{"location":"chapter4/notes/#simplex-based-proof-sketch-standard-form","title":"Simplex-based proof sketch (standard form)","text":"<p>Consider the standard-form primal - minimize \\(e^\\top x\\) - subject to \\(Ax=b\\), \\(x\\ge 0\\).  </p> <p>When simplex terminates, it returns an optimal basis \\(B\\) and \\(x_B = B^{-1}b\\). Define the dual candidate by \\(p^\\top = e_B^\\top B^{-1}\\).</p> <ul> <li>Dual feasibility: termination implies all reduced costs are nonnegative, which is equivalent to \\(p^\\top A \\le e^\\top\\).  </li> <li>Equal objective values: \\(p^\\top b = e_B^\\top B^{-1}b = e_B^\\top x_B = e^\\top x\\).</li> </ul> <p>So we have primal-feasible \\(x\\) and dual-feasible \\(p\\) with equal costs, hence both are optimal.</p>"},{"location":"chapter4/notes/#435-example-44-mechanical-analogy","title":"4.3.5 Example 4.4 (mechanical analogy)","text":"<p>Intuition box \u2014 Ball in a polyhedron</p> <p>Think of the feasible region as walls that constrain a ball. Gravity points in direction \\(c\\), so equilibrium occurs at the \u201clowest\u201d point \\(x^*\\), i.e., an optimal solution.</p> <p>At equilibrium, supporting forces from the active walls balance gravity, giving a representation like \\(c = \\sum_i p_i a_i\\) with \\(p_i \\ge 0\\). This corresponds to dual feasibility.</p> <p>Walls that do not touch the ball exert no force, so if \\(a_i^\\top x^* &gt; b_i\\) then \\(p_i=0\\). This is the intuition behind conditions of the form \\(p_i(a_i^\\top x^* - b_i)=0\\).</p> <p>With these forces, one gets a matching of objective values: \\((p^*)^\\top b = c^\\top x^*\\), which certifies optimality.</p>"},{"location":"chapter4/notes/#436-what-can-happen-to-primal-dual","title":"4.3.6 What can happen to (primal, dual)?","text":"<p>Key box \u2014 The three statuses</p> <p>Each of the primal and dual can be: - Optimal solution exists, or - Unbounded (minimization: value \\(=-\\infty\\); maximization: value \\(=+\\infty\\)), or - Infeasible.</p> <p>Strong duality says: if one has an optimal solution, so does the other, and the optimal values are equal. Weak duality says: if one is unbounded, the other must be infeasible.</p> <p>Example box \u2014 Both can be infeasible</p> <p>Primal (infeasible): - minimize \\(x_1 + 2x_2\\) - subject to \\(x_1 + x_2 = 1\\), and \\(2x_1 + 2x_2 = 3\\)</p> <p>Dual (also infeasible): - maximize \\(p_1 + 3p_2\\) - subject to \\(p_1 + 2p_2 = 1\\), and \\(p_1 + 2p_2 = 2\\)</p> <p>Remark box \u2014 Clark\u2019s theorem</p> <p>Unless both problems are infeasible, at least one of them must have an unbounded feasible set (as referenced in the text/exercise).</p>"}]}